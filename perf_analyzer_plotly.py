#!/usr/bin/env python3
"""
GPUæ€§èƒ½æµ‹è¯•å¯¹æ¯”æ•°æ®ç»Ÿè®¡å›¾è¡¨ç”Ÿæˆå·¥å…· (Plotlyç‰ˆæœ¬)
æ”¯æŒå¤šä¸ªCSVæ–‡ä»¶è¾“å…¥ï¼Œå¯¹æ¯”ä¸åŒGPUçš„å¹¶è¡Œè®¡ç®—ç®—æ³•æ€§èƒ½
"""

import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np
import argparse
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional

class PerformanceAnalyzer:
    def __init__(self):
        self.datasets = {}  # {label: dataframe}
    
    def _get_rgb_from_name(self, color_name):
        """å°†é¢œè‰²åç§°è½¬æ¢ä¸ºRGBå€¼"""
        color_map = {
            'red': '255, 0, 0',
            'green': '0, 128, 0', 
            'blue': '0, 0, 255',
            'orange': '255, 165, 0',
            'purple': '128, 0, 128',
            'brown': '139, 69, 19',
            'pink': '255, 192, 203',
            'gray': '128, 128, 128',
            'olive': '128, 128, 0',
            'cyan': '0, 255, 255'
        }
        return color_map.get(color_name, '0, 0, 0')  # é»˜è®¤é»‘è‰²
        
    def load_dataset(self, csv_path: str, label: str):
        """
        åŠ è½½CSVæ•°æ®é›†å¹¶æŒ‡å®šæ ‡ç­¾(å¦‚GPUåç§°)
        
        CSVæ ¼å¼è¦æ±‚:
        - algorithm: ç®—æ³•åç§° (å¦‚sort, reduce, scanç­‰)
        - data_size: æ•°æ®é‡è§„æ¨¡ (ä»¥MBä¸ºå•ä½çš„æ•°å€¼ï¼Œå¦‚1, 16, 1024)
        - throughput: ååé‡ (GB/s)
        """
        try:
            df = pd.read_csv(csv_path)
            
            # éªŒè¯å¿…éœ€çš„åˆ—
            required_columns = ['algorithm', 'data_size', 'throughput']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(f"CSVæ–‡ä»¶ {csv_path} ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
            
            # ç¡®ä¿data_sizeæ˜¯æ•°å€¼ç±»å‹
            df['data_size'] = pd.to_numeric(df['data_size'], errors='coerce')
            
            # æ·»åŠ æ ‡ç­¾åˆ—
            df['gpu_label'] = label
            self.datasets[label] = df
            
            print(f"æˆåŠŸåŠ è½½æ•°æ®é›†: {label} ({len(df)} æ¡è®°å½•)")
            return df
            
        except Exception as e:
            print(f"åŠ è½½æ•°æ®é›†å¤±è´¥ {csv_path}: {e}")
            return None
    
    def get_combined_dataframe(self) -> pd.DataFrame:
        """åˆå¹¶æ‰€æœ‰æ•°æ®é›†"""
        if not self.datasets:
            return pd.DataFrame()
        
        combined_df = pd.concat(self.datasets.values(), ignore_index=True)
        return combined_df
    
    def create_comparison_line_chart(self, save_path: str = None, width: int = 1200, height: int = 800):
        """
        åˆ›å»ºå¤šGPUæ€§èƒ½å¯¹æ¯”æŠ˜çº¿å›¾
        æ¯ä¸ªç®—æ³•ä¸€æ¡çº¿ï¼Œä¸åŒGPUç”¨ä¸åŒé¢œè‰²/æ ·å¼åŒºåˆ†
        """
        df = self.get_combined_dataframe()
        
        if df.empty:
            print("æ²¡æœ‰æ•°æ®å¯ä»¥ç»˜åˆ¶")
            return None
        
        # åˆ›å»ºå›¾è¡¨
        fig = go.Figure()
        
        # è·å–å”¯ä¸€çš„ç®—æ³•å’ŒGPUæ ‡ç­¾
        algorithms = df['algorithm'].unique()
        gpu_labels = df['gpu_label'].unique()
        
        # é¢œè‰²å’Œçº¿å‹é…ç½®
        colors = px.colors.qualitative.Set1
        line_styles = ['solid', 'dash', 'dot', 'dashdot']
        
        for i, gpu in enumerate(gpu_labels):
            gpu_data = df[df['gpu_label'] == gpu]
            
            for j, algorithm in enumerate(algorithms):
                algo_data = gpu_data[gpu_data['algorithm'] == algorithm]
                
                if algo_data.empty:
                    continue
                
                # æŒ‰æ•°æ®é‡æ’åº
                algo_data = algo_data.sort_values('data_size')
                
                # åˆ›å»ºè½¨è¿¹
                trace_name = f"{gpu} - {algorithm}"
                
                # åˆ›å»ºè‡ªå®šä¹‰hover textæ˜¾ç¤ºæ•°æ®å¤§å°æ ‡ç­¾
                def mb_to_label(mb_value):
                    if mb_value < 1:
                        return f"{int(mb_value * 1024)}KB"
                    elif mb_value < 1024:
                        return f"{int(mb_value)}MB"
                    else:
                        return f"{int(mb_value / 1024)}GB"
                
                hover_labels = [mb_to_label(x) for x in algo_data['data_size']]
                
                fig.add_trace(go.Scatter(
                    x=algo_data['data_size'],
                    y=algo_data['throughput'],
                    mode='lines+markers',
                    name=trace_name,
                    line=dict(
                        color=colors[j % len(colors)],
                        dash=line_styles[i % len(line_styles)],
                        width=2
                    ),
                    marker=dict(
                        size=8,
                        symbol=['circle', 'square', 'diamond', 'triangle-up'][i % 4]
                    ),
                    customdata=hover_labels,
                    hovertemplate=(
                        f"<b>{trace_name}</b><br>"
                        "Data Size: %{customdata}<br>"
                        "Throughput: %{y:.2f} GB/s<br>"
                        "<extra></extra>"
                    )
                ))
        
        # æ›´æ–°å¸ƒå±€
        fig.update_layout(
            title=dict(
                text="GPU Performance Comparison - Parallel Computing Algorithms",
                x=0.5,
                font=dict(size=20)
            ),
            xaxis=dict(
                title=dict(text="Data Size (MB)", font=dict(size=14)),
                tickfont=dict(size=12),
                type="log",  # ä½¿ç”¨å¯¹æ•°åæ ‡
                tickmode='array',
                tickvals=[0.004, 0.008, 0.016, 0.032, 0.064, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096],
                ticktext=['4KB', '8KB', '16KB', '32KB', '64KB', '128KB', '256KB', '512KB', '1MB', '2MB', '4MB', '8MB', '16MB', '32MB', '64MB', '128MB', '256MB', '512MB', '1GB', '2GB', '4GB']
            ),
            yaxis=dict(
                title=dict(text="Throughput (GB/s)", font=dict(size=14)),
                tickfont=dict(size=12),
                type="log"  # ä½¿ç”¨å¯¹æ•°åæ ‡
            ),
            legend=dict(
                orientation="v",
                yanchor="top",
                y=1,
                xanchor="left",
                x=1.02,
                font=dict(size=11)
            ),
            width=width,
            height=height,
            hovermode='closest',
            plot_bgcolor='white',
            paper_bgcolor='white'
        )
        
        # æ·»åŠ ç½‘æ ¼
        fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
        fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
        
        # ä¿å­˜å›¾è¡¨
        if save_path:
            if save_path.endswith('.html'):
                fig.write_html(save_path)
                print(f"äº¤äº’å¼å›¾è¡¨å·²ä¿å­˜: {save_path}")
            else:
                fig.write_image(save_path, width=width, height=height)
                print(f"é™æ€å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        # ä¸è‡ªåŠ¨æ˜¾ç¤ºå›¾è¡¨ï¼Œé¿å…è¾“å‡ºHTMLå†…å®¹
        return fig
    
    def calculate_percentage_differences(self, extreme_threshold=300):
        """
        è®¡ç®—ç›¸å¯¹äºç¬¬ä¸€ä¸ªGPUçš„æ€§èƒ½ç™¾åˆ†æ¯”å·®å¼‚
        
        Args:
            extreme_threshold: æç«¯æ•°æ®é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼çš„å·®å¼‚å°†è¢«æ ‡è®°ä¸ºæç«¯æ•°æ®
        
        Returns:
            tuple: (normal_data_df, extreme_data_list, anomaly_data_list) - æ­£å¸¸æ•°æ®ã€æç«¯æ•°æ®å’Œå¼‚å¸¸æ•°æ®
        """
        df = self.get_combined_dataframe()
        if df.empty or len(df['gpu_label'].unique()) <= 1:
            return None, [], []
        
        gpu_labels = df['gpu_label'].unique()
        if len(gpu_labels) < 2:
            return None, [], []
        
        # ä»¥ç¬¬ä¸€ä¸ªGPUä¸ºåŸºå‡†
        baseline_gpu = gpu_labels[0]
        comparison_gpus = gpu_labels[1:]
        
        percentage_data = []
        extreme_data = []
        anomaly_data = []
        
        # è·å–æ‰€æœ‰ç®—æ³•å’Œæ•°æ®å¤§å°çš„ç»„åˆ
        algorithms = df['algorithm'].unique()
        data_sizes = df['data_size'].unique()
        
        for algorithm in algorithms:
            for data_size in data_sizes:
                # è·å–åŸºå‡†æ€§èƒ½
                baseline_mask = (df['gpu_label'] == baseline_gpu) & \
                               (df['algorithm'] == algorithm) & \
                               (df['data_size'] == data_size)
                baseline_data = df[baseline_mask]
                
                if baseline_data.empty:
                    continue
                
                baseline_throughput = baseline_data['throughput'].iloc[0]
                
                # è®¡ç®—å…¶ä»–GPUçš„ç™¾åˆ†æ¯”å·®å¼‚
                for gpu in comparison_gpus:
                    comparison_mask = (df['gpu_label'] == gpu) & \
                                     (df['algorithm'] == algorithm) & \
                                     (df['data_size'] == data_size)
                    comparison_data = df[comparison_mask]
                    
                    if comparison_data.empty:
                        continue
                    
                    comparison_throughput = comparison_data['throughput'].iloc[0]
                    
                    # æ£€æŸ¥å¼‚å¸¸æ•°æ®
                    import numpy as np
                    is_anomaly = False
                    anomaly_reason = ""
                    
                    # æ£€æŸ¥åŸºå‡†æ•°æ®å¼‚å¸¸
                    if (baseline_throughput <= 0 or 
                        np.isnan(baseline_throughput) or 
                        np.isinf(baseline_throughput)):
                        is_anomaly = True
                        anomaly_reason = f"å¼‚å¸¸åŸºå‡†å€¼: {baseline_throughput}"
                    
                    # æ£€æŸ¥å¯¹æ¯”æ•°æ®å¼‚å¸¸
                    elif (comparison_throughput <= 0 or 
                          np.isnan(comparison_throughput) or 
                          np.isinf(comparison_throughput)):
                        is_anomaly = True
                        anomaly_reason = f"å¼‚å¸¸å¯¹æ¯”å€¼: {comparison_throughput}"
                    
                    if is_anomaly:
                        # è®°å½•å¼‚å¸¸æ•°æ®
                        anomaly_data.append({
                            'algorithm': algorithm,
                            'data_size': data_size,
                            'gpu_label': gpu,
                            'baseline_throughput': baseline_throughput,
                            'comparison_throughput': comparison_throughput,
                            'reason': anomaly_reason
                        })
                        continue
                    
                    # è®¡ç®—ç™¾åˆ†æ¯”å·®å¼‚
                    percentage_diff = ((comparison_throughput - baseline_throughput) / baseline_throughput) * 100
                    
                    # æ£€æŸ¥è®¡ç®—ç»“æœæ˜¯å¦å¼‚å¸¸
                    if np.isnan(percentage_diff) or np.isinf(percentage_diff):
                        anomaly_data.append({
                            'algorithm': algorithm,
                            'data_size': data_size,
                            'gpu_label': gpu,
                            'baseline_throughput': baseline_throughput,
                            'comparison_throughput': comparison_throughput,
                            'reason': f"è®¡ç®—ç»“æœå¼‚å¸¸: {percentage_diff}"
                        })
                        continue
                    
                    data_point = {
                        'algorithm': algorithm,
                        'data_size': data_size,
                        'gpu_label': gpu,
                        'percentage_diff': percentage_diff,
                        'baseline_throughput': baseline_throughput,
                        'comparison_throughput': comparison_throughput
                    }
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæç«¯æ•°æ®
                    if abs(percentage_diff) > extreme_threshold:
                        extreme_data.append(data_point)
                    else:
                        percentage_data.append(data_point)
        
        return pd.DataFrame(percentage_data), extreme_data, anomaly_data

    def create_comparison_line_chart(self, save_path: str = None, width: int = 1200, height: int = 800):
        """
        åˆ›å»ºå¤šGPUæ€§èƒ½å¯¹æ¯”æŠ˜çº¿å›¾å’Œç™¾åˆ†æ¯”å·®å¼‚å›¾
        åŒ…å«åŸå§‹æ€§èƒ½å›¾å’Œç›¸å¯¹äºç¬¬ä¸€ä¸ªGPUçš„ç™¾åˆ†æ¯”å·®å¼‚å›¾
        """
        df = self.get_combined_dataframe()
        
        if df.empty:
            print("æ²¡æœ‰æ•°æ®å¯ä»¥ç»˜åˆ¶")
            return None
        
        # è·å–GPUæ ‡ç­¾æ•°é‡
        gpu_labels = df['gpu_label'].unique()
        has_multiple_gpus = len(gpu_labels) > 1
        
        # å¦‚æœæœ‰å¤šä¸ªGPUï¼Œåˆ›å»ºå­å›¾ï¼›å¦åˆ™åªåˆ›å»ºå•ä¸ªå›¾è¡¨
        if has_multiple_gpus:
            # æ ¹æ®GPUæ•°é‡å†³å®šå­å›¾å¸ƒå±€
            comparison_gpus = gpu_labels[1:]
            num_comparisons = len(comparison_gpus)
            
            # åŠ¨æ€å¸ƒå±€ï¼šæ ¹æ®å¯¹æ¯”ç»„æ•°é‡åˆ›å»ºå­å›¾
            # ç¬¬ä¸€è¡Œï¼šåŸå§‹æ€§èƒ½å¯¹æ¯”
            # ç¬¬äºŒè¡Œï¼šç™¾åˆ†æ¯”å·®å¼‚å¯¹æ¯”
            # ç¬¬ä¸‰è¡Œå¼€å§‹ï¼šæ¯ä¸ªå¯¹æ¯”ç»„ä¸€ä¸ªç›´æ–¹å›¾å­å›¾
            
            total_rows = 2 + num_comparisons  # å‰ä¸¤è¡Œ + æ¯ä¸ªå¯¹æ¯”ç»„çš„ç›´æ–¹å›¾
            comparison_cols = min(num_comparisons, 3)  # æœ€å¤š3åˆ—ç›´æ–¹å›¾
            comparison_rows = (num_comparisons + comparison_cols - 1) // comparison_cols  # è®¡ç®—éœ€è¦çš„è¡Œæ•°
            
            # åˆ›å»ºå­å›¾æ ‡é¢˜
            subplot_titles = [
                'åŸå§‹æ€§èƒ½å¯¹æ¯”',
                f'ç›¸å¯¹äº {gpu_labels[0]} çš„æ€§èƒ½ç™¾åˆ†æ¯”å·®å¼‚'
            ]
            
            # ä¸ºæ¯ä¸ªå¯¹æ¯”ç»„æ·»åŠ ç›´æ–¹å›¾æ ‡é¢˜
            for i, gpu in enumerate(comparison_gpus):
                subplot_titles.append(f'{gpu} vs {gpu_labels[0]} - å·®å¼‚åˆ†å¸ƒç›´æ–¹å›¾')
            
            # è®¡ç®—å¸ƒå±€è§„æ ¼
            if num_comparisons == 1:
                # å•å¯¹æ¯”ï¼š3è¡Œ1åˆ—
                fig = make_subplots(
                    rows=3, cols=1,
                    subplot_titles=subplot_titles,
                    vertical_spacing=0.12,
                    specs=[[{"secondary_y": False}], [{"secondary_y": False}], [{"secondary_y": False}]],
                    row_heights=[0.35, 0.35, 0.3]
                )
                total_height = int(height * 2.2)
            elif num_comparisons == 2:
                # åŒå¯¹æ¯”ï¼š3è¡Œ2åˆ—ï¼ˆç¬¬ä¸‰è¡Œæ”¾2ä¸ªç›´æ–¹å›¾ï¼‰
                fig = make_subplots(
                    rows=3, cols=2,
                    subplot_titles=subplot_titles,
                    vertical_spacing=0.12,
                    horizontal_spacing=0.1,
                    specs=[[{"secondary_y": False, "colspan": 2}, None], 
                           [{"secondary_y": False, "colspan": 2}, None],
                           [{"secondary_y": False}, {"secondary_y": False}]],
                    row_heights=[0.35, 0.35, 0.3]
                )
                total_height = int(height * 2.2)
                width = int(width * 1.3)
            else:
                # å¤šå¯¹æ¯”ï¼šé‡‡ç”¨æ›´çµæ´»çš„å¸ƒå±€
                cols = min(num_comparisons, 3)
                histogram_rows = (num_comparisons + cols - 1) // cols
                total_rows = 2 + histogram_rows
                
                # æ„å»ºspecs
                specs = []
                # å‰ä¸¤è¡Œè·¨æ‰€æœ‰åˆ—
                specs.append([{"secondary_y": False, "colspan": cols}] + [None] * (cols - 1))
                specs.append([{"secondary_y": False, "colspan": cols}] + [None] * (cols - 1))
                
                # ç›´æ–¹å›¾è¡Œ
                for row in range(histogram_rows):
                    row_specs = []
                    for col in range(cols):
                        idx = row * cols + col
                        if idx < num_comparisons:
                            row_specs.append({"secondary_y": False})
                        else:
                            row_specs.append(None)
                    specs.append(row_specs)
                
                # è®¡ç®—è¡Œé«˜
                row_heights = [0.25, 0.25] + [0.5 / histogram_rows] * histogram_rows
                
                fig = make_subplots(
                    rows=total_rows, cols=cols,
                    subplot_titles=subplot_titles,
                    vertical_spacing=0.08,
                    horizontal_spacing=0.08,
                    specs=specs,
                    row_heights=row_heights
                )
                total_height = int(height * (1.5 + 0.5 * histogram_rows))
                width = int(width * 1.4)
        else:
            # åªæœ‰ä¸€ä¸ªGPUæ—¶ï¼Œåˆ›å»ºå•ä¸ªå›¾è¡¨
            fig = go.Figure()
            total_height = height
        
        # è·å–å”¯ä¸€çš„ç®—æ³•å’ŒGPUæ ‡ç­¾
        algorithms = df['algorithm'].unique()
        
        # é¢œè‰²å’Œçº¿å‹é…ç½®
        colors = px.colors.qualitative.Set1
        line_styles = ['solid', 'dash', 'dot', 'dashdot']
        
        # åˆ›å»ºè‡ªå®šä¹‰hover textæ˜¾ç¤ºæ•°æ®å¤§å°æ ‡ç­¾çš„å‡½æ•°
        def mb_to_label(mb_value):
            if mb_value < 1:
                return f"{int(mb_value * 1024)}KB"
            elif mb_value < 1024:
                return f"{int(mb_value)}MB"
            else:
                return f"{int(mb_value / 1024)}GB"
        
        # æ·»åŠ åŸå§‹æ€§èƒ½æ•°æ®åˆ°ç¬¬ä¸€ä¸ªå­å›¾ï¼ˆæˆ–å”¯ä¸€çš„å›¾è¡¨ï¼‰
        for i, gpu in enumerate(gpu_labels):
            gpu_data = df[df['gpu_label'] == gpu]
            
            for j, algorithm in enumerate(algorithms):
                algo_data = gpu_data[gpu_data['algorithm'] == algorithm]
                
                if algo_data.empty:
                    continue
                
                # æŒ‰æ•°æ®é‡æ’åº
                algo_data = algo_data.sort_values('data_size')
                
                # åˆ›å»ºè½¨è¿¹
                trace_name = f"{gpu} - {algorithm}"
                
                hover_labels = [mb_to_label(x) for x in algo_data['data_size']]
                
                scatter_trace = go.Scatter(
                    x=algo_data['data_size'],
                    y=algo_data['throughput'],
                    mode='lines+markers',
                    name=trace_name,
                    line=dict(
                        color=colors[j % len(colors)],
                        dash=line_styles[i % len(line_styles)],
                        width=2
                    ),
                    marker=dict(
                        size=8,
                        symbol=['circle', 'square', 'diamond', 'triangle-up'][i % 4]
                    ),
                    customdata=hover_labels,
                    hovertemplate=(
                        f"<b>{trace_name}</b><br>"
                        "Data Size: %{customdata}<br>"
                        "Throughput: %{y:.2f} GB/s<br>"
                        "<extra></extra>"
                    )
                )
                
                if has_multiple_gpus:
                    fig.add_trace(scatter_trace, row=1, col=1)
                else:
                    fig.add_trace(scatter_trace)
        
        # å¦‚æœæœ‰å¤šä¸ªGPUï¼Œæ·»åŠ ç™¾åˆ†æ¯”å·®å¼‚å›¾åˆ°ç¬¬äºŒä¸ªå­å›¾
        if has_multiple_gpus:
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            
            if percentage_df is not None and not percentage_df.empty:
                baseline_gpu = gpu_labels[0]
                comparison_gpus = gpu_labels[1:]
                
                colors_comparison = px.colors.qualitative.Set2
                
                for i, gpu in enumerate(comparison_gpus):
                    gpu_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    
                    for j, algorithm in enumerate(algorithms):
                        algo_data = gpu_data[gpu_data['algorithm'] == algorithm]
                        
                        if algo_data.empty:
                            continue
                        
                        # æŒ‰æ•°æ®é‡æ’åº
                        algo_data = algo_data.sort_values('data_size')
                        
                        # åˆ›å»ºç™¾åˆ†æ¯”å·®å¼‚è½¨è¿¹
                        trace_name = f"{gpu} vs {baseline_gpu} - {algorithm}"
                        
                        hover_labels = [mb_to_label(x) for x in algo_data['data_size']]
                        
                        percentage_trace = go.Scatter(
                            x=algo_data['data_size'],
                            y=algo_data['percentage_diff'],
                            mode='lines+markers',
                            name=f"{gpu} vs {baseline_gpu} - {algorithm}",
                            line=dict(
                                color=colors_comparison[j % len(colors_comparison)],
                                dash=line_styles[i % len(line_styles)],
                                width=2
                            ),
                            marker=dict(
                                size=8,
                                symbol=['circle', 'square', 'diamond', 'triangle-up'][i % 4]
                            ),
                            customdata=hover_labels,
                            hovertemplate=(
                                f"<b>{gpu} vs {baseline_gpu} - {algorithm}</b><br>"
                                "Data Size: %{customdata}<br>"
                                "Performance Difference: %{y:+.1f}%<br>"
                                "Baseline: %{customdata[0]:.2f} GB/s<br>"
                                "Comparison: %{customdata[1]:.2f} GB/s<br>"
                                "<extra></extra>"
                            )
                        )
                        
                        # æ›´æ–°hoveræ•°æ®ä»¥åŒ…å«ååé‡ä¿¡æ¯
                        hover_data = []
                        for _, row in algo_data.iterrows():
                            hover_data.append([
                                mb_to_label(row['data_size']),
                                row['baseline_throughput'],
                                row['comparison_throughput']
                            ])
                        
                        percentage_trace.customdata = hover_data
                        
                        fig.add_trace(percentage_trace, row=2, col=1)
        
        # æ›´æ–°å¸ƒå±€
        if has_multiple_gpus:
            # å¤šGPUæ—¶çš„å¸ƒå±€è®¾ç½®
            fig.update_layout(
                title=dict(
                    text="GPU Performance Comparison - Original and Percentage Differences",
                    x=0.5,
                    font=dict(size=20)
                ),
                width=width,
                height=total_height,
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white',
                # è®¾ç½®ç›´æ–¹å›¾æŸ±é—´è·å’Œç»„é—´è·
                bargap=0.2,      # åŒç»„å†…æŸ±é—´è·
                bargroupgap=0.1  # ä¸åŒç»„é—´è·
            )
            
            # æ›´æ–°ç¬¬ä¸€ä¸ªå­å›¾çš„è½´æ ‡ç­¾
            fig.update_xaxes(
                title=dict(text="Data Size (MB)", font=dict(size=14)),
                type="log",
                tickmode='array',
                tickvals=[0.004, 0.008, 0.016, 0.032, 0.064, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096],
                ticktext=['4KB', '8KB', '16KB', '32KB', '64KB', '128KB', '256KB', '512KB', '1MB', '2MB', '4MB', '8MB', '16MB', '32MB', '64MB', '128MB', '256MB', '512MB', '1GB', '2GB', '4GB'],
                row=1, col=1
            )
            fig.update_yaxes(
                title=dict(text="Throughput (GB/s)", font=dict(size=14)),
                type="log",
                row=1, col=1
            )
            
            # æ›´æ–°ç¬¬äºŒä¸ªå­å›¾çš„è½´æ ‡ç­¾
            fig.update_xaxes(
                title=dict(text="Data Size (MB)", font=dict(size=14)),
                type="log",
                tickmode='array',
                tickvals=[0.004, 0.008, 0.016, 0.032, 0.064, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096],
                ticktext=['4KB', '8KB', '16KB', '32KB', '64KB', '128KB', '256KB', '512KB', '1MB', '2MB', '4MB', '8MB', '16MB', '32MB', '64MB', '128MB', '256MB', '512MB', '1GB', '2GB', '4GB'],
                row=2, col=1
            )
            fig.update_yaxes(
                title=dict(text="Performance Difference (%)", font=dict(size=14)),
                row=2, col=1
            )
            
            # ä¸ºæ¯ä¸ªç›´æ–¹å›¾å­å›¾æ·»åŠ ç½‘æ ¼
            for i, gpu in enumerate(comparison_gpus):
                if num_comparisons == 1:
                    hist_row, hist_col = 3, 1
                elif num_comparisons == 2:
                    hist_row, hist_col = 3, i + 1
                else:
                    cols = min(num_comparisons, 3)
                    hist_row = 3 + i // cols
                    hist_col = (i % cols) + 1
                
                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=hist_row, col=hist_col)
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=hist_row, col=hist_col)
            
            # æ·»åŠ é›¶çº¿åˆ°ç™¾åˆ†æ¯”å›¾
            fig.add_hline(y=0, line_dash="dash", line_color="black", line_width=1, row=2, col=1)
            
            # ä¸ºæ¯ä¸ªå¯¹æ¯”ç»„åˆ›å»ºç‹¬ç«‹çš„ç›´æ–¹å›¾å­å›¾
            if percentage_df is not None and not percentage_df.empty:
                # åˆ›å»ºè‡ªå®šä¹‰hoveræ–‡æœ¬æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                def mb_to_label(mb_value):
                    if mb_value < 1:
                        return f"{int(mb_value * 1024)}KB"
                    elif mb_value < 1024:
                        return f"{int(mb_value)}MB"
                    else:
                        return f"{int(mb_value / 1024)}GB"
                
                comparison_gpus = gpu_labels[1:]
                
                # ä¸ºæ¯ä¸ªå¯¹æ¯”ç»„åˆ›å»ºç‹¬ç«‹çš„ç›´æ–¹å›¾å’Œæ•£ç‚¹å›¾
                for i, gpu in enumerate(comparison_gpus):
                    gpu_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    
                    if gpu_data.empty:
                        continue
                    
                    # ç¡®å®šå­å›¾ä½ç½®
                    if num_comparisons == 1:
                        hist_row, hist_col = 3, 1
                    elif num_comparisons == 2:
                        hist_row, hist_col = 3, i + 1
                    else:
                        # å¤šå¯¹æ¯”å¸ƒå±€
                        cols = min(num_comparisons, 3)
                        hist_row = 3 + i // cols
                        hist_col = (i % cols) + 1
                    
                    # 1. æ·»åŠ ç›´æ–¹å›¾æ˜¾ç¤ºæ•´ä½“åˆ†å¸ƒ
                    histogram_trace = go.Histogram(
                        x=gpu_data['percentage_diff'],
                        nbinsx=20,
                        name=f'{gpu} åˆ†å¸ƒ',
                        opacity=0.7,
                        marker=dict(
                            color='rgba(30, 144, 255, 0.7)',
                            line=dict(color='rgba(30, 144, 255, 1)', width=1)
                        ),
                        showlegend=True,
                        hovertemplate=(
                            f"<b>{gpu} vs {gpu_labels[0]} åˆ†å¸ƒ</b><br>"
                            "æ€§èƒ½å·®å¼‚èŒƒå›´: %{x}<br>"
                            "æ•°æ®ç‚¹æ•°é‡: %{y}<br>"
                            "<extra></extra>"
                        )
                    )
                    fig.add_trace(histogram_trace, row=hist_row, col=hist_col)
                    
                    # 2. è®¡ç®—ç›´æ–¹å›¾çš„æŸ±ä½“åˆ†å¸ƒï¼Œç”¨äºæ•£ç‚¹çš„å‚ç›´å®šä½
                    import numpy as np
                    
                    # è®¡ç®—ç›´æ–¹å›¾çš„binså’Œcounts
                    percentage_values = gpu_data['percentage_diff'].values
                    hist_counts, bin_edges = np.histogram(percentage_values, bins=20)
                    bin_width = bin_edges[1] - bin_edges[0]
                    
                    # æŒ‰ç®—æ³•åˆ†ç»„ï¼Œå°†ç›¸åŒç®—æ³•çš„æ•°æ®ç‚¹æ”¾åœ¨æ¥è¿‘ä½ç½®
                    # 1. é¦–å…ˆå°†æ•°æ®æŒ‰binåˆ†ç»„
                    bins_data = {}
                    for _, row in gpu_data.iterrows():
                        x_value = row['percentage_diff']
                        bin_index = min(int((x_value - bin_edges[0]) / bin_width), len(hist_counts) - 1)
                        bin_index = max(0, bin_index)
                        
                        if bin_index not in bins_data:
                            bins_data[bin_index] = []
                        bins_data[bin_index].append(row)
                    
                    # 2. ä¸ºæ¯ä¸ªbinå†…çš„æ•°æ®æŒ‰ç®—æ³•åˆ†ç»„å¹¶åˆ†é…Yåæ ‡
                    scatter_points = []
                    for bin_index, bin_rows in bins_data.items():
                        bin_height = hist_counts[bin_index]
                        if bin_height == 0:
                            bin_height = 1  # æœ€å°é«˜åº¦
                        
                        # æŒ‰ç®—æ³•åˆ†ç»„
                        algo_groups = {}
                        for row in bin_rows:
                            algo = row['algorithm']
                            if algo not in algo_groups:
                                algo_groups[algo] = []
                            algo_groups[algo].append(row)
                        
                        # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…Yè½´å±‚çº§
                        algorithms = sorted(algo_groups.keys())  # æŒ‰å­—æ¯åºæ’åºä¿æŒä¸€è‡´æ€§
                        num_algorithms = len(algorithms)
                        
                        for algo_idx, algorithm in enumerate(algorithms):
                            algo_data = algo_groups[algorithm]
                            
                            # è®¡ç®—è¯¥ç®—æ³•åœ¨binä¸­çš„Yè½´èŒƒå›´
                            y_layer_start = (bin_height / num_algorithms) * algo_idx
                            y_layer_end = (bin_height / num_algorithms) * (algo_idx + 1)
                            
                            # åœ¨ç®—æ³•å±‚å†…æŒ‰æ•°æ®é‡æ’åº
                            algo_data.sort(key=lambda x: x['data_size'])
                            
                            # ä¸ºç®—æ³•å†…çš„æ¯ä¸ªæ•°æ®ç‚¹åˆ†é…Yåæ ‡
                            for data_idx, row in enumerate(algo_data):
                                x_value = row['percentage_diff']
                                
                                # åœ¨ç®—æ³•å±‚å†…å‡åŒ€åˆ†å¸ƒ
                                if len(algo_data) > 1:
                                    y_ratio = data_idx / (len(algo_data) - 1)
                                else:
                                    y_ratio = 0.5  # å•ä¸ªæ•°æ®ç‚¹å±…ä¸­
                                
                                # åœ¨ç®—æ³•å±‚èŒƒå›´å†…åˆ†å¸ƒï¼Œç•™å‡º10%è¾¹ç•Œ
                                layer_height = y_layer_end - y_layer_start
                                y_value = y_layer_start + layer_height * (0.1 + y_ratio * 0.8)
                                
                                # è®¡ç®—å½“å‰binçš„Xè½´è¾¹ç•Œ
                                bin_left = bin_edges[bin_index]
                                bin_right = bin_edges[bin_index + 1] if bin_index + 1 < len(bin_edges) else bin_edges[-1]
                                
                                # ç¡®ä¿Xè½´æŠ–åŠ¨ä¸è¶…å‡ºbinè¾¹ç•Œ
                                max_x_jitter = min(
                                    x_value - bin_left,      # è·å·¦è¾¹ç•Œçš„è·ç¦»
                                    bin_right - x_value,     # è·å³è¾¹ç•Œçš„è·ç¦»
                                    bin_width * 0.3          # æœ€å¤§æŠ–åŠ¨èŒƒå›´
                                ) * 0.8  # ç•™å‡º20%çš„å®‰å…¨è¾¹ç•Œ
                                
                                # Yè½´æŠ–åŠ¨ç¡®ä¿åœ¨ç®—æ³•å±‚å†…
                                y_jitter = np.random.uniform(-layer_height * 0.03, layer_height * 0.03)
                                x_jitter = np.random.uniform(-max_x_jitter, max_x_jitter)
                                
                                final_x = x_value + x_jitter
                                final_y = y_value + y_jitter
                                
                                # åŒé‡æ£€æŸ¥ï¼šç¡®ä¿æ•£ç‚¹åœ¨æ­£ç¡®çš„è¾¹ç•Œå†…
                                final_x = max(bin_left + bin_width * 0.05, min(bin_right - bin_width * 0.05, final_x))
                                final_y = max(y_layer_start + layer_height * 0.02, min(y_layer_end - layer_height * 0.02, final_y))
                                
                                scatter_points.append({
                                    'x': final_x,
                                    'y': max(0.1, final_y),
                                    'algorithm': row['algorithm'],
                                    'data_size': mb_to_label(row['data_size']),
                                    'baseline_throughput': row['baseline_throughput'],
                                    'comparison_throughput': row['comparison_throughput'],
                                    'percentage_diff': row['percentage_diff']  # ä¿æŒåŸå§‹å€¼ç”¨äºhover
                                })
                    
                    if scatter_points:
                        scatter_df = pd.DataFrame(scatter_points)
                        
                        # æ ¹æ®ç®—æ³•è®¾ç½®ä¸åŒçš„é¢œè‰²å’Œå½¢çŠ¶
                        algorithms = scatter_df['algorithm'].unique()
                        algorithm_colors = {}
                        algorithm_symbols = {}
                        
                        # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²å’Œç¬¦å·
                        available_colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'gray', 'olive', 'cyan']
                        available_symbols = ['circle', 'square', 'diamond', 'cross', 'triangle-up', 'triangle-down', 'star', 'hexagon', 'pentagon', 'x']
                        
                        for j, algo in enumerate(algorithms):
                            algorithm_colors[algo] = available_colors[j % len(available_colors)]
                            algorithm_symbols[algo] = available_symbols[j % len(available_symbols)]
                        
                        # ä¸ºæ¯ä¸ªç®—æ³•åˆ›å»ºä¸€ä¸ªæ•£ç‚¹trace
                        for algo in algorithms:
                            algo_data = scatter_df[scatter_df['algorithm'] == algo]
                            
                            # æ ¹æ®æ€§èƒ½å·®å¼‚è°ƒæ•´é€æ˜åº¦
                            colors_with_alpha = []
                            for diff in algo_data['x']:
                                base_color = algorithm_colors[algo]
                                alpha = 0.9 if abs(diff) > 10 else 0.6  # å·®å¼‚å¤§çš„ç‚¹æ›´æ˜¾è‘—
                                colors_with_alpha.append(f'rgba({self._get_rgb_from_name(base_color)}, {alpha})')
                            
                            scatter_trace = go.Scatter(
                                x=algo_data['x'],
                                y=algo_data['y'],
                                mode='markers',
                                name=f'{algo} ({gpu})',
                                marker=dict(
                                    size=10,
                                    color=colors_with_alpha,
                                    symbol=algorithm_symbols[algo],
                                    line=dict(color='white', width=1)
                                ),
                                customdata=list(zip(
                                    algo_data['algorithm'],
                                    algo_data['data_size'],
                                    algo_data['baseline_throughput'],
                                    algo_data['comparison_throughput'],
                                    algo_data['percentage_diff']  # ä½¿ç”¨åŸå§‹çš„æ€§èƒ½å·®å¼‚å€¼
                                )),
                                hovertemplate=(
                                    f"<b>{gpu} vs {gpu_labels[0]}</b><br>"
                                    "ç®—æ³•: %{customdata[0]}<br>"
                                    "æ•°æ®é‡: %{customdata[1]}<br>"
                                    "æ€§èƒ½å·®å¼‚: %{customdata[4]:+.1f}%<br>"
                                    f"{gpu_labels[0]}: %{{customdata[2]:.2f}} GB/s<br>"
                                    f"{gpu}: %{{customdata[3]:.2f}} GB/s<br>"
                                    "<extra></extra>"
                                ),
                                showlegend=True
                            )
                            fig.add_trace(scatter_trace, row=hist_row, col=hist_col)
                    
                    # 3. æ·»åŠ ç»Ÿè®¡å‚è€ƒçº¿ï¼Œæ™ºèƒ½é¿å…æ ‡æ³¨é‡å 
                    mean_diff = gpu_data['percentage_diff'].mean()
                    median_diff = gpu_data['percentage_diff'].median()
                    
                    # è®¡ç®—æ•°æ®èŒƒå›´ç”¨äºæ™ºèƒ½å®šä½æ ‡æ³¨
                    data_min = gpu_data['percentage_diff'].min()
                    data_max = gpu_data['percentage_diff'].max()
                    data_range = data_max - data_min
                    
                    # æ™ºèƒ½é€‰æ‹©æ ‡æ³¨ä½ç½®ï¼Œé¿å…é‡å å’Œä¸æ ‡é¢˜å†²çª  
                    # å¦‚æœå‡å€¼å’Œä¸­ä½æ•°å¾ˆæ¥è¿‘ï¼Œé”™å¼€æ˜¾ç¤ºä½ç½®
                    mean_median_gap = abs(mean_diff - median_diff)
                    
                    if mean_median_gap < data_range * 0.1:  # å·®è·å°äºæ•°æ®èŒƒå›´çš„10%
                        # å·®è·è¾ƒå°æ—¶ï¼Œä¸€ä¸ªåœ¨ä¸Šä¸€ä¸ªåœ¨ä¸‹ï¼Œå¹¶ç¨å¾®åç§»
                        mean_position = "top right" if mean_diff > median_diff else "top left"
                        median_position = "bottom left" if mean_diff > median_diff else "bottom right"
                    else:
                        # å·®è·è¾ƒå¤§æ—¶ï¼Œéƒ½å¯ä»¥åœ¨ä¸Šæ–¹ï¼Œä½†å·¦å³åˆ†å¼€
                        mean_position = "top left"
                        median_position = "top right"
                    
                    # æ·»åŠ å‡å€¼çº¿
                    fig.add_vline(
                        x=mean_diff, 
                        line_dash="dash", 
                        line_color="red", 
                        annotation_text=f"å‡å€¼: {mean_diff:.1f}%", 
                        annotation_position=mean_position,
                        annotation=dict(
                            font=dict(size=10, color="red"),
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor="red",
                            borderwidth=1
                        ),
                        row=hist_row, col=hist_col
                    )
                    
                    # æ·»åŠ ä¸­ä½æ•°çº¿
                    fig.add_vline(
                        x=median_diff, 
                        line_dash="dot", 
                        line_color="green", 
                        annotation_text=f"ä¸­ä½æ•°: {median_diff:.1f}%", 
                        annotation_position=median_position,
                        annotation=dict(
                            font=dict(size=10, color="green"),
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor="green",  
                            borderwidth=1
                        ),
                        row=hist_row, col=hist_col
                    )
                    
                    # æ·»åŠ é›¶çº¿ï¼ˆåŸºå‡†çº¿ï¼‰
                    fig.add_vline(
                        x=0, 
                        line_dash="solid", 
                        line_color="black", 
                        line_width=2,
                        annotation_text="åŸºå‡†çº¿",
                        annotation_position="bottom",
                        annotation=dict(
                            font=dict(size=9, color="black"),
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor="black",
                            borderwidth=1
                        ),
                        row=hist_row, col=hist_col
                    )
                    
                    # æ›´æ–°ç›´æ–¹å›¾å­å›¾çš„è½´æ ‡ç­¾
                    fig.update_xaxes(
                        title_text="æ€§èƒ½å·®å¼‚ç™¾åˆ†æ¯” (%)", 
                        row=hist_row, col=hist_col
                    )
                    fig.update_yaxes(
                        title_text="é¢‘æ¬¡ / æ•°æ®ç‚¹", 
                        row=hist_row, col=hist_col
                    )
                
                # æ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š
                negative_data = percentage_df[percentage_df['percentage_diff'] < 0]
                if not negative_data.empty:
                    negative_count = len(negative_data)
                    total_count = len(percentage_df)
                    negative_ratio = (negative_count / total_count) * 100
                    
                    print(f"âš ï¸  æ€§èƒ½è½å: {negative_count} ä¸ªæ•°æ®ç‚¹ ({negative_ratio:.1f}%)")
                    
                    # æŒ‰ç®—æ³•åˆ†ç»„æ˜¾ç¤ºè´Ÿå€¼ç»Ÿè®¡
                    neg_by_algo = negative_data.groupby('algorithm').size().sort_values(ascending=False)
                    for algo, count in neg_by_algo.head(3).items():
                        print(f"  {algo}: {count} ä¸ª")
            
            # æ·»åŠ ç½‘æ ¼åˆ°å‰ä¸¤ä¸ªå­å›¾
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=1, col=1)
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=1, col=1)
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=2, col=1)
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=2, col=1)
            
        else:
            # å•GPUæ—¶çš„å¸ƒå±€è®¾ç½®
            fig.update_layout(
                title=dict(
                    text="GPU Performance - Single GPU Analysis",
                    x=0.5,
                    font=dict(size=20)
                ),
                xaxis=dict(
                    title=dict(text="Data Size (MB)", font=dict(size=14)),
                    type="log",
                    tickmode='array',
                    tickvals=[0.004, 0.016, 0.064, 0.256, 1, 4, 16, 64, 256, 1024, 2048, 4096],
                    ticktext=['4KB', '16KB', '64KB', '256KB', '1MB', '4MB', '16MB', '64MB', '256MB', '1GB', '2GB', '4GB']
                ),
                yaxis=dict(
                    title=dict(text="Throughput (GB/s)", font=dict(size=14)),
                    type="log"
                ),
                legend=dict(
                    orientation="v",
                    yanchor="top",
                    y=1,
                    xanchor="left",
                    x=1.02,
                    font=dict(size=11)
                ),
                width=width,
                height=total_height,
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white'
            )
            
            # æ·»åŠ ç½‘æ ¼
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
        
        # ä¿å­˜å›¾è¡¨
        if save_path:
            if save_path.endswith('.html'):
                # ç”ŸæˆåŒ…å«ç»Ÿè®¡è¡¨æ ¼çš„å®Œæ•´HTML
                self._write_html_with_statistics(fig, save_path)
                print(f"äº¤äº’å¼å›¾è¡¨å·²ä¿å­˜: {save_path}")
            else:
                fig.write_image(save_path, width=width, height=total_height)
                print(f"é™æ€å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        # ä¸è‡ªåŠ¨æ˜¾ç¤ºå›¾è¡¨ï¼Œé¿å…è¾“å‡ºHTMLå†…å®¹
        return fig

    def generate_statistics_tables(self) -> str:
        """ç”ŸæˆHTMLç»Ÿè®¡åˆ†ææ•°æ®è¡¨"""
        if not self.datasets:
            return "<p>æ— æ•°æ®å¯æ˜¾ç¤º</p>"
        
        html_content = []
        
        # è·å–åˆå¹¶æ•°æ®
        df = self.get_combined_dataframe()
        if df.empty:
            return "<p>æ— æ•°æ®å¯æ˜¾ç¤º</p>"
        
        gpu_labels = list(self.datasets.keys())
        algorithms = df['algorithm'].unique()
        
        # 1. GPUæ€§èƒ½å¯¹æ¯”æ€»è¡¨
        html_content.append('<div class="statistics-section">')
        html_content.append('<h3>ğŸ“Š GPUæ€§èƒ½å¯¹æ¯”æ€»è§ˆ</h3>')
        html_content.append('<table class="stats-table">')
        html_content.append('<thead><tr><th>GPU</th><th>å¹³å‡ååé‡ (GB/s)</th><th>æœ€é«˜ååé‡ (GB/s)</th><th>æ•°æ®ç‚¹æ•°é‡</th><th>ä¸»è¦ä¼˜åŠ¿ç®—æ³•</th></tr></thead>')
        html_content.append('<tbody>')
        
        for gpu in gpu_labels:
            gpu_data = df[df['gpu_label'] == gpu]
            if not gpu_data.empty:
                avg_throughput = gpu_data['throughput'].mean()
                max_throughput = gpu_data['throughput'].max()
                max_row = gpu_data[gpu_data['throughput'] == max_throughput].iloc[0]
                data_count = len(gpu_data)
                
                # æ‰¾å‡ºè¯¥GPUè¡¨ç°æœ€å¥½çš„ç®—æ³•
                algo_avg = gpu_data.groupby('algorithm')['throughput'].mean().sort_values(ascending=False)
                top_algorithms = ', '.join(algo_avg.head(3).index.tolist())
                
                html_content.append(f'<tr>')
                html_content.append(f'<td><strong>{gpu}</strong></td>')
                html_content.append(f'<td>{avg_throughput:.2f}</td>')
                html_content.append(f'<td>{max_throughput:.2f}<br><small>({max_row["algorithm"]}, {max_row["data_size"]:.0f}MB)</small></td>')
                html_content.append(f'<td>{data_count}</td>')
                html_content.append(f'<td><small>{top_algorithms}</small></td>')
                html_content.append(f'</tr>')
        
        html_content.append('</tbody></table>')
        html_content.append('</div>')
        
        # 2. ç®—æ³•æ€§èƒ½åˆ†æè¡¨
        html_content.append('<div class="statistics-section">')
        html_content.append('<h3>ğŸ”¬ ç®—æ³•æ€§èƒ½åˆ†æ</h3>')
        html_content.append('<table class="stats-table">')
        html_content.append('<thead><tr><th>ç®—æ³•</th>')
        
        for gpu in gpu_labels:
            html_content.append(f'<th>{gpu}<br><small>(GB/s)</small></th>')
        
        html_content.append('<th>ç®—æ³•å¹³å‡</th><th>æœ€ä½³GPU</th></tr></thead>')
        html_content.append('<tbody>')
        
        for algo in sorted(algorithms):
            html_content.append('<tr>')
            html_content.append(f'<td><strong>{algo}</strong></td>')
            
            algo_data = df[df['algorithm'] == algo]
            gpu_performances = []
            
            for gpu in gpu_labels:
                gpu_algo_data = algo_data[algo_data['gpu_label'] == gpu]
                if not gpu_algo_data.empty:
                    avg_perf = gpu_algo_data['throughput'].mean()
                    gpu_performances.append((gpu, avg_perf))
                    html_content.append(f'<td>{avg_perf:.2f}</td>')
                else:
                    gpu_performances.append((gpu, 0))
                    html_content.append(f'<td>-</td>')
            
            # ç®—æ³•æ•´ä½“å¹³å‡
            algo_avg = algo_data['throughput'].mean()
            html_content.append(f'<td><strong>{algo_avg:.2f}</strong></td>')
            
            # æœ€ä½³GPU
            if gpu_performances:
                best_gpu = max(gpu_performances, key=lambda x: x[1])
                if best_gpu[1] > 0:
                    html_content.append(f'<td><span class="best-gpu">{best_gpu[0]}</span><br><small>{best_gpu[1]:.2f}</small></td>')
                else:
                    html_content.append(f'<td>-</td>')
            else:
                html_content.append(f'<td>-</td>')
                
            html_content.append('</tr>')
        
        html_content.append('</tbody></table>')
        html_content.append('</div>')
        
        # 3. æ€§èƒ½å·®å¼‚åˆ†æè¡¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
        if len(gpu_labels) > 1:
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            if percentage_df is not None and not percentage_df.empty:
                html_content.append('<div class="statistics-section">')
                html_content.append('<h3>ğŸ“ˆ æ€§èƒ½å·®å¼‚åˆ†æ</h3>')
                
                baseline_gpu = gpu_labels[0]
                comparison_gpus = gpu_labels[1:]
                
                for gpu in comparison_gpus:
                    gpu_diff_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    if gpu_diff_data.empty:
                        continue
                        
                    html_content.append(f'<h4>{gpu} vs {baseline_gpu}</h4>')
                    html_content.append('<table class="stats-table">')
                    html_content.append('<thead><tr><th>ç»Ÿè®¡æŒ‡æ ‡</th><th>æ•°å€¼</th><th>è¯´æ˜</th></tr></thead>')
                    html_content.append('<tbody>')
                    
                    # åŸºæœ¬ç»Ÿè®¡
                    mean_diff = gpu_diff_data['percentage_diff'].mean()
                    median_diff = gpu_diff_data['percentage_diff'].median()
                    std_diff = gpu_diff_data['percentage_diff'].std()
                    min_diff = gpu_diff_data['percentage_diff'].min()
                    max_diff = gpu_diff_data['percentage_diff'].max()
                    
                    # æ€§èƒ½ä¼˜åŠ¿ç»Ÿè®¡
                    positive_count = len(gpu_diff_data[gpu_diff_data['percentage_diff'] > 0])
                    negative_count = len(gpu_diff_data[gpu_diff_data['percentage_diff'] < 0])
                    total_count = len(gpu_diff_data)
                    
                    stats_data = [
                        ('å¹³å‡å·®å¼‚', f'{mean_diff:+.1f}%', 'æ­£å€¼è¡¨ç¤ºæ€§èƒ½æå‡ï¼Œè´Ÿå€¼è¡¨ç¤ºæ€§èƒ½ä¸‹é™'),
                        ('ä¸­ä½æ•°å·®å¼‚', f'{median_diff:+.1f}%', '50%çš„æµ‹è¯•ç‚¹æ€§èƒ½å·®å¼‚åœ¨æ­¤å€¼ä»¥ä¸‹'),
                        ('æ ‡å‡†å·®', f'{std_diff:.1f}%', 'æ€§èƒ½å·®å¼‚çš„ç¦»æ•£ç¨‹åº¦'),
                        ('æœ€å¤§æå‡', f'{max_diff:+.1f}%', 'å•ä¸ªæµ‹è¯•ç‚¹çš„æœ€å¤§æ€§èƒ½æå‡'),
                        ('æœ€å¤§ä¸‹é™', f'{min_diff:+.1f}%', 'å•ä¸ªæµ‹è¯•ç‚¹çš„æœ€å¤§æ€§èƒ½ä¸‹é™'),
                        ('æ€§èƒ½æå‡æ¯”ä¾‹', f'{positive_count}/{total_count} ({100*positive_count/total_count:.1f}%)', 'è¡¨ç°æ›´å¥½çš„æµ‹è¯•ç‚¹æ¯”ä¾‹'),
                        ('æ€§èƒ½ä¸‹é™æ¯”ä¾‹', f'{negative_count}/{total_count} ({100*negative_count/total_count:.1f}%)', 'è¡¨ç°è¾ƒå·®çš„æµ‹è¯•ç‚¹æ¯”ä¾‹')
                    ]
                    
                    for stat_name, stat_value, stat_desc in stats_data:
                        color_class = ""
                        if "æå‡" in stat_name and "+" in stat_value:
                            color_class = ' class="positive"'
                        elif "ä¸‹é™" in stat_name and "-" in stat_value:
                            color_class = ' class="negative"'
                            
                        html_content.append(f'<tr>')
                        html_content.append(f'<td><strong>{stat_name}</strong></td>')
                        html_content.append(f'<td{color_class}><strong>{stat_value}</strong></td>')
                        html_content.append(f'<td><small>{stat_desc}</small></td>')
                        html_content.append(f'</tr>')
                    
                    html_content.append('</tbody></table><br>')
                
                html_content.append('</div>')
        
        # 4. æ•°æ®è§„æ¨¡åˆ†æè¡¨
        html_content.append('<div class="statistics-section">')
        html_content.append('<h3>ğŸ“ æ•°æ®è§„æ¨¡æ€§èƒ½åˆ†æ</h3>')
        html_content.append('<table class="stats-table">')
        html_content.append('<thead><tr><th>æ•°æ®è§„æ¨¡</th>')
        
        for gpu in gpu_labels:
            html_content.append(f'<th>{gpu}<br><small>å¹³å‡ (GB/s)</small></th>')
        
        html_content.append('<th>è§„æ¨¡å¹³å‡</th><th>æœ€ä½³è¡¨ç°</th></tr></thead>')
        html_content.append('<tbody>')
        
        data_sizes = sorted(df['data_size'].unique())
        for size in data_sizes:
            size_data = df[df['data_size'] == size]
            
            # æ ¼å¼åŒ–æ•°æ®è§„æ¨¡æ˜¾ç¤º
            if size < 1:
                size_label = f"{int(size * 1024)}KB"
            elif size < 1024:
                size_label = f"{int(size)}MB"
            else:
                size_label = f"{int(size / 1024)}GB"
            
            html_content.append('<tr>')
            html_content.append(f'<td><strong>{size_label}</strong></td>')
            
            size_performances = []
            
            for gpu in gpu_labels:
                gpu_size_data = size_data[size_data['gpu_label'] == gpu]
                if not gpu_size_data.empty:
                    avg_perf = gpu_size_data['throughput'].mean()
                    size_performances.append((gpu, avg_perf))
                    html_content.append(f'<td>{avg_perf:.2f}</td>')
                else:
                    size_performances.append((gpu, 0))
                    html_content.append(f'<td>-</td>')
            
            # è§„æ¨¡å¹³å‡
            size_avg = size_data['throughput'].mean()
            html_content.append(f'<td><strong>{size_avg:.2f}</strong></td>')
            
            # æœ€ä½³è¡¨ç°
            if size_performances:
                best_gpu_size = max(size_performances, key=lambda x: x[1])
                if best_gpu_size[1] > 0:
                    html_content.append(f'<td><span class="best-gpu">{best_gpu_size[0]}</span><br><small>{best_gpu_size[1]:.2f}</small></td>')
                else:
                    html_content.append(f'<td>-</td>')
            else:
                html_content.append(f'<td>-</td>')
                
            html_content.append('</tr>')
        
        html_content.append('</tbody></table>')
        html_content.append('</div>')
        
        # 5. æç«¯å’Œå¼‚å¸¸æ•°æ®æŠ¥å‘Šï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
        if len(gpu_labels) > 1:
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            
            # æç«¯æ•°æ®å±•ç¤º
            if extreme_data:
                html_content.append('<div class="statistics-section">')
                html_content.append('<h3>âš ï¸ æç«¯æ€§èƒ½å·®å¼‚æ•°æ® (>300%)</h3>')
                html_content.append(f'<p><small>å…±å‘ç° <strong>{len(extreme_data)}</strong> ä¸ªæç«¯æ€§èƒ½å·®å¼‚æ•°æ®ç‚¹ï¼Œå·²ä»å¸¸è§„å¯¹æ¯”åˆ†æä¸­æ’é™¤</small></p>')
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºæç«¯æ•°æ®
                extreme_by_gpu = {}
                for item in extreme_data:
                    gpu = item['gpu_label']
                    if gpu not in extreme_by_gpu:
                        extreme_by_gpu[gpu] = []
                    extreme_by_gpu[gpu].append(item)
                
                for gpu, gpu_extreme_data in extreme_by_gpu.items():
                    html_content.append(f'<h4>{gpu} vs {gpu_labels[0]} - æç«¯æ¡ˆä¾‹ ({len(gpu_extreme_data)} ä¸ª)</h4>')
                    html_content.append('<table class="stats-table">')
                    html_content.append('<thead><tr><th>ç®—æ³•</th><th>æ•°æ®è§„æ¨¡</th><th>æ€§èƒ½å·®å¼‚</th><th>åŸºå‡†å€¼</th><th>å¯¹æ¯”å€¼</th></tr></thead>')
                    html_content.append('<tbody>')
                    
                    # æŒ‰å·®å¼‚ç¨‹åº¦æ’åºï¼Œåªæ˜¾ç¤ºå‰10ä¸ª
                    gpu_extreme_data.sort(key=lambda x: abs(x['percentage_diff']), reverse=True)
                    for item in gpu_extreme_data[:10]:
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        
                        diff_class = 'positive' if item['percentage_diff'] > 0 else 'negative'
                        html_content.append('<tr>')
                        html_content.append(f'<td>{item["algorithm"]}</td>')
                        html_content.append(f'<td>{data_size_label}</td>')
                        html_content.append(f'<td class="{diff_class}"><strong>{item["percentage_diff"]:+.1f}%</strong></td>')
                        html_content.append(f'<td>{item["baseline_throughput"]:.2f} GB/s</td>')
                        html_content.append(f'<td>{item["comparison_throughput"]:.2f} GB/s</td>')
                        html_content.append('</tr>')
                    
                    if len(gpu_extreme_data) > 10:
                        html_content.append(f'<tr><td colspan="5"><small><em>... è¿˜æœ‰ {len(gpu_extreme_data) - 10} ä¸ªæç«¯æ¡ˆä¾‹</em></small></td></tr>')
                    
                    html_content.append('</tbody></table><br>')
                
                html_content.append('</div>')
            
            # å¼‚å¸¸æ•°æ®å±•ç¤º
            if anomaly_data:
                html_content.append('<div class="statistics-section">')
                html_content.append('<h3>ğŸš« å¼‚å¸¸æ•°æ® (æ— æ•ˆå€¼)</h3>')
                html_content.append(f'<p><small>å…±å‘ç° <strong>{len(anomaly_data)}</strong> ä¸ªåŒ…å«æ— æ•ˆå€¼çš„æ•°æ®ç‚¹ï¼Œå·²ä»æ‰€æœ‰åˆ†æä¸­æ’é™¤</small></p>')
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºå¼‚å¸¸æ•°æ®
                anomaly_by_gpu = {}
                for item in anomaly_data:
                    gpu = item['gpu_label']
                    if gpu not in anomaly_by_gpu:
                        anomaly_by_gpu[gpu] = []
                    anomaly_by_gpu[gpu].append(item)
                
                for gpu, gpu_anomaly_data in anomaly_by_gpu.items():
                    html_content.append(f'<h4>{gpu} vs {gpu_labels[0]} - å¼‚å¸¸æ¡ˆä¾‹ ({len(gpu_anomaly_data)} ä¸ª)</h4>')
                    html_content.append('<table class="stats-table">')
                    html_content.append('<thead><tr><th>ç®—æ³•</th><th>æ•°æ®è§„æ¨¡</th><th>å¼‚å¸¸åŸå› </th><th>åŸºå‡†å€¼</th><th>å¯¹æ¯”å€¼</th></tr></thead>')
                    html_content.append('<tbody>')
                    
                    # åªæ˜¾ç¤ºå‰15ä¸ªå¼‚å¸¸æ¡ˆä¾‹
                    for item in gpu_anomaly_data[:15]:
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        
                        html_content.append('<tr>')
                        html_content.append(f'<td>{item["algorithm"]}</td>')
                        html_content.append(f'<td>{data_size_label}</td>')
                        html_content.append(f'<td class="negative"><small>{item["reason"]}</small></td>')
                        html_content.append(f'<td>{item["baseline_throughput"]:.2f} GB/s</td>')
                        html_content.append(f'<td>{item["comparison_throughput"]:.2f} GB/s</td>')
                        html_content.append('</tr>')
                    
                    if len(gpu_anomaly_data) > 15:
                        html_content.append(f'<tr><td colspan="5"><small><em>... è¿˜æœ‰ {len(gpu_anomaly_data) - 15} ä¸ªå¼‚å¸¸æ¡ˆä¾‹</em></small></td></tr>')
                    
                    html_content.append('</tbody></table><br>')
                
                html_content.append('</div>')
        
        return '\n'.join(html_content)

    def _get_html_styles(self) -> str:
        """è·å–è¡¨æ ¼æ ·å¼CSS"""
        return """
        <style>
        .statistics-container {
            max-width: 1200px;
            margin: 20px auto;
            padding: 20px;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f8f9fa;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .statistics-section {
            margin-bottom: 30px;
            background: white;
            padding: 20px;
            border-radius: 6px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        
        .statistics-section h3 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-top: 0;
            font-size: 1.4em;
        }
        
        .statistics-section h4 {
            color: #34495e;
            margin-top: 25px;
            margin-bottom: 15px;
            font-size: 1.2em;
            border-left: 4px solid #e74c3c;
            padding-left: 12px;
        }
        
        .stats-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
            font-size: 0.9em;
        }
        
        .stats-table th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 8px;
            text-align: center;
            font-weight: 600;
            border: 1px solid #ddd;
            font-size: 0.85em;
        }
        
        .stats-table td {
            padding: 10px 8px;
            text-align: center;
            border: 1px solid #ddd;
            background-color: #fff;
        }
        
        .stats-table tbody tr:nth-child(even) {
            background-color: #f8f9fa;
        }
        
        .stats-table tbody tr:hover {
            background-color: #e8f4f8;
            transition: background-color 0.2s;
        }
        
        .best-gpu {
            background: linear-gradient(45deg, #28a745, #20c997);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-weight: bold;
            font-size: 0.8em;
            display: inline-block;
        }
        
        .positive {
            color: #28a745;
            font-weight: bold;
        }
        
        .negative {
            color: #dc3545;
            font-weight: bold;
        }
        
        .stats-table td small {
            color: #6c757d;
            font-size: 0.8em;
            display: block;
            margin-top: 2px;
        }
        
        .stats-table th small {
            font-weight: normal;
            font-size: 0.75em;
            opacity: 0.9;
        }
        
        /* å“åº”å¼è®¾è®¡ */
        @media (max-width: 768px) {
            .statistics-container {
                margin: 10px;
                padding: 10px;
            }
            
            .stats-table {
                font-size: 0.8em;
            }
            
            .stats-table th,
            .stats-table td {
                padding: 6px 4px;
            }
        }
        </style>
        """

    def _write_html_with_statistics(self, fig, save_path: str):
        """å°†å›¾è¡¨å’Œç»Ÿè®¡è¡¨æ ¼å†™å…¥HTMLæ–‡ä»¶"""
        import tempfile
        import os
        
        # å…ˆå°†å›¾è¡¨ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False) as tmp_file:
            fig.write_html(tmp_file.name)
            
            # è¯»å–Plotlyç”Ÿæˆçš„HTMLå†…å®¹
            with open(tmp_file.name, 'r', encoding='utf-8') as f:
                plotly_html = f.read()
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_file.name)
        
        # ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼
        statistics_html = self.generate_statistics_tables()
        
        # è·å–æ ·å¼
        styles = self._get_html_styles()
        
        # åœ¨Plotly HTMLä¸­æ’å…¥ç»Ÿè®¡è¡¨æ ¼å’Œæ ·å¼
        # æ‰¾åˆ°</head>æ ‡ç­¾ï¼Œåœ¨ä¹‹å‰æ’å…¥æ ·å¼
        if '</head>' in plotly_html:
            plotly_html = plotly_html.replace('</head>', f'{styles}</head>')
        
        # æ‰¾åˆ°</body>æ ‡ç­¾ï¼Œåœ¨ä¹‹å‰æ’å…¥ç»Ÿè®¡è¡¨æ ¼
        statistics_section = f'''
        <div class="statistics-container">
            <h2 style="text-align: center; color: #2c3e50; margin-bottom: 30px;">
                ğŸ“ˆ GPUæ€§èƒ½ç»Ÿè®¡åˆ†ææŠ¥å‘Š
            </h2>
            {statistics_html}
        </div>
        '''
        
        if '</body>' in plotly_html:
            plotly_html = plotly_html.replace('</body>', f'{statistics_section}</body>')
        
        # å†™å…¥æœ€ç»ˆçš„HTMLæ–‡ä»¶
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(plotly_html)

    def generate_summary_report(self) -> str:
        """ç”Ÿæˆæ€§èƒ½åˆ†ææ€»ç»“æŠ¥å‘Š"""
        df = self.get_combined_dataframe()
        
        if df.empty:
            return "æ²¡æœ‰æ•°æ®å¯ä»¥åˆ†æ"
        
        report = []
        report.append("=" * 50)
        report.append("Performance Analysis Report")
        report.append("=" * 50)
        report.append(f"Total samples: {len(df)}")
        report.append(f"Algorithms tested: {', '.join(df['algorithm'].unique())}")
        report.append(f"GPU labels: {', '.join(df['gpu_label'].unique())}")
        report.append(f"Data sizes: {', '.join(map(str, df['data_size'].unique()))}")
        report.append("")
        
        # æœ€ä½³æ€§èƒ½ç»Ÿè®¡
        best_perf = df.loc[df['throughput'].idxmax()]
        report.append("Best Performance:")
        report.append(f"  Algorithm: {best_perf['algorithm']}")
        report.append(f"  GPU: {best_perf['gpu_label']}")
        report.append(f"  Data Size: {best_perf['data_size']}")
        report.append(f"  Throughput: {best_perf['throughput']:.2f} GB/s")
        report.append("")
        
        # å„GPUå¹³å‡æ€§èƒ½
        report.append("Average Performance by GPU:")
        for gpu in df['gpu_label'].unique():
            avg_perf = df[df['gpu_label'] == gpu]['throughput'].mean()
            report.append(f"  {gpu}: {avg_perf:.2f} GB/s")
        report.append("")
        
        # æ€§èƒ½ç™¾åˆ†æ¯”å·®å¼‚åˆ†æï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
        gpu_labels = df['gpu_label'].unique()
        if len(gpu_labels) > 1:
            report.append("Performance Percentage Differences:")
            report.append(f"  Baseline GPU: {gpu_labels[0]}")
            report.append("")
            
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            if percentage_df is not None:
                for gpu in gpu_labels[1:]:
                    gpu_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    if not gpu_data.empty:
                        avg_diff = gpu_data['percentage_diff'].mean()
                        max_diff = gpu_data['percentage_diff'].max()
                        min_diff = gpu_data['percentage_diff'].min()
                        report.append(f"  {gpu} vs {gpu_labels[0]}:")
                        report.append(f"    Average: {avg_diff:+.1f}%")
                        report.append(f"    Max: {max_diff:+.1f}%")
                        report.append(f"    Min: {min_diff:+.1f}%")
                        report.append("")
            
            # æ·»åŠ æç«¯æ•°æ®æŠ¥å‘Š
            if extreme_data:
                report.append("Extreme Performance Differences (>300%):")
                report.append(f"  Total extreme data points: {len(extreme_data)}")
                report.append("")
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºæç«¯æ•°æ®
                extreme_by_gpu = {}
                for item in extreme_data:
                    gpu = item['gpu_label']
                    if gpu not in extreme_by_gpu:
                        extreme_by_gpu[gpu] = []
                    extreme_by_gpu[gpu].append(item)
                
                for gpu, gpu_extreme_data in extreme_by_gpu.items():
                    report.append(f"  {gpu} vs {gpu_labels[0]} - Extreme Cases:")
                    # æŒ‰å·®å¼‚ç¨‹åº¦æ’åº
                    gpu_extreme_data.sort(key=lambda x: abs(x['percentage_diff']), reverse=True)
                    
                    for item in gpu_extreme_data[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªæœ€æç«¯çš„
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        report.append(f"    {item['algorithm']} ({data_size_label}): {item['percentage_diff']:+.1f}% "
                                    f"({item['baseline_throughput']:.2f} â†’ {item['comparison_throughput']:.2f} GB/s)")
                    
                    if len(gpu_extreme_data) > 10:
                        report.append(f"    ... and {len(gpu_extreme_data) - 10} more extreme cases")
                    report.append("")
            
            # æ·»åŠ å¼‚å¸¸æ•°æ®æŠ¥å‘Š
            if anomaly_data:
                report.append("Anomalous Data (invalid values):")
                report.append(f"  Total anomalous data points: {len(anomaly_data)}")
                report.append("")
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºå¼‚å¸¸æ•°æ®
                anomaly_by_gpu = {}
                for item in anomaly_data:
                    gpu = item['gpu_label']
                    if gpu not in anomaly_by_gpu:
                        anomaly_by_gpu[gpu] = []
                    anomaly_by_gpu[gpu].append(item)
                
                for gpu, gpu_anomaly_data in anomaly_by_gpu.items():
                    report.append(f"  {gpu} vs {gpu_labels[0]} - Anomalous Cases:")
                    
                    for item in gpu_anomaly_data[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ªå¼‚å¸¸æ¡ˆä¾‹
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        report.append(f"    {item['algorithm']} ({data_size_label}): {item['reason']} "
                                    f"({item['baseline_throughput']:.2f} vs {item['comparison_throughput']:.2f} GB/s)")
                    
                    if len(gpu_anomaly_data) > 15:
                        report.append(f"    ... and {len(gpu_anomaly_data) - 15} more anomalous cases")
                    report.append("")
        
        # å„ç®—æ³•å¹³å‡æ€§èƒ½
        report.append("Average Performance by Algorithm:")
        for algo in df['algorithm'].unique():
            avg_perf = df[df['algorithm'] == algo]['throughput'].mean()
            report.append(f"  {algo}: {avg_perf:.2f} GB/s")
        
        return "\n".join(report)


def create_comprehensive_datasets():
    """åˆ›å»ºç»¼åˆæ€§èƒ½æ•°æ®é›†ï¼ŒåŒ…å«æ›´å¤šç®—æ³•ç±»åˆ«å’Œæ•°æ®è§„æ¨¡"""
    
    # æ‰©å±•çš„å¹¶è¡Œè®¡ç®—ç®—æ³•ç±»åˆ«
    algorithms = {
        # åŸºç¡€å¹¶è¡Œç®—æ³•
        'sort': 'Parallel Sorting',
        'reduce': 'Parallel Reduction', 
        'scan': 'Prefix Sum/Scan',
        'histogram': 'Histogram Computing',
        'compact': 'Stream Compaction',
        
        # çº¿æ€§ä»£æ•°ç®—æ³•
        'matmul': 'Matrix Multiplication',
        'gemv': 'Matrix-Vector Multiply',
        'gemm': 'General Matrix Multiply',
        'spmv': 'Sparse Matrix-Vector',
        'trsv': 'Triangular Solve',
        
        # å›¾åƒ/ä¿¡å·å¤„ç†ç®—æ³•
        'conv2d': '2D Convolution',
        'conv3d': '3D Convolution',
        'fft': 'Fast Fourier Transform',
        'gaussian_blur': 'Gaussian Blur',
        'bilateral_filter': 'Bilateral Filter',
        
        # æœºå™¨å­¦ä¹ ç®—æ³•
        'dnn_training': 'DNN Training',
        'dnn_inference': 'DNN Inference',
        'cnn_forward': 'CNN Forward Pass',
        'cnn_backward': 'CNN Backward Pass',
        'transformer_attn': 'Transformer Attention',
        
        # ç§‘å­¦è®¡ç®—ç®—æ³•
        'stencil_2d': '2D Stencil Computation',
        'stencil_3d': '3D Stencil Computation',
        'molecular_dynamics': 'Molecular Dynamics',
        'monte_carlo': 'Monte Carlo Simulation',
        'n_body': 'N-Body Simulation'
    }
    
    # æ‰©å±•çš„æ•°æ®è§„æ¨¡èŒƒå›´ (å‡ KBåˆ°å‡ GB) - ä»¥MBä¸ºå•ä½çš„æ•°å€¼ï¼Œä»¥2å€é€’å¢
    data_sizes_mb = [
        0.004, 0.008, 0.016, 0.032, 0.064, 0.125, 0.25, 0.5, 1, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096
    ]
    
    # å¯¹åº”çš„æ˜¾ç¤ºæ ‡ç­¾  
    data_size_labels = [
        '4KB', '8KB', '16KB', '32KB', '64KB', '128KB', '256KB', '512KB', 
        '1MB', '2MB', '4MB', '8MB', '16MB', '32MB', '64MB', '128MB', 
        '256MB', '512MB', '1GB', '2GB', '4GB'
    ]
    
    # GPUå‹å·åŠå…¶æ€§èƒ½ç‰¹å¾ (åªæµ‹è¯•3ä¸ªGPU)
    gpu_configs = {
        'RTX_4090': {
            'name': 'RTX_4090',
            'memory_bandwidth': 1008,  # GB/s
            'compute_units': 128,
            'base_clock': 2230,  # MHz
            'memory_size': 24,   # GB
        },
        'A100': {
            'name': 'A100',
            'memory_bandwidth': 1935,
            'compute_units': 108,
            'base_clock': 1410,
            'memory_size': 80,
        },
        'H100': {
            'name': 'H100',
            'memory_bandwidth': 3350,
            'compute_units': 132,
            'base_clock': 1980,
            'memory_size': 80,
        }
    }
    
    np.random.seed(42)
    
    def mb_to_bytes(size_mb):
        """å°†MBä¸ºå•ä½çš„æ•°å€¼è½¬æ¢ä¸ºå­—èŠ‚æ•°"""
        return size_mb * 1024 * 1024
    
    def calculate_roofline_performance(algorithm, data_size_mb, gpu_config):
        """ç®€åŒ–çš„rooflineæ¨¡å‹ï¼šy=a*x çº¿æ€§å…³ç³»"""
        
        # ç®—æ³•ç‰¹æ€§ç³»æ•° - ä¸åŒç®—æ³•æœ‰ä¸åŒçš„çº¿æ€§ç³»æ•°ï¼Œå¯èƒ½äº’æœ‰èƒœè´Ÿ
        algorithm_coefficients = {
            # åŸºç¡€å¹¶è¡Œç®—æ³•
            'sort': 6.8, 'reduce': 8.2, 'scan': 7.5, 'histogram': 5.9, 'compact': 6.4,
            # çº¿æ€§ä»£æ•°ç®—æ³•  
            'matmul': 9.1, 'gemv': 7.8, 'gemm': 9.5, 'spmv': 6.2, 'trsv': 7.3,
            # å›¾åƒå¤„ç†ç®—æ³•
            'conv2d': 8.7, 'conv3d': 9.3, 'fft': 7.1, 'gaussian_blur': 8.0, 'bilateral_filter': 8.4,
            # æœºå™¨å­¦ä¹ ç®—æ³•
            'dnn_training': 9.8, 'dnn_inference': 8.6, 'cnn_forward': 9.2, 'cnn_backward': 9.6, 'transformer_attn': 8.9,
            # ç§‘å­¦è®¡ç®—ç®—æ³•
            'stencil_2d': 7.6, 'stencil_3d': 8.1, 'molecular_dynamics': 8.5, 'monte_carlo': 8.8, 'n_body': 8.3
        }
        
        # GPUå·®å¼‚ç³»æ•° - ä¸åŒGPUå·®è·ä¸å¤§ï¼Œå¤§çº¦20%èŒƒå›´å†…
        gpu_multipliers = {
            'RTX_4090': 1.0,    # åŸºå‡†
            'A100': 1.08,       # ç¨é«˜8%
            'H100': 1.04        # ç¨é«˜4%
        }
        
        # è·å–ç®—æ³•ç³»æ•°å’ŒGPUç³»æ•°
        a = algorithm_coefficients.get(algorithm, 7.5)  # é»˜è®¤ç³»æ•°7.5
        gpu_factor = gpu_multipliers.get(gpu_config.get('name', 'RTX_4090'), 1.0)
        
        data_mb = data_size_mb
        
        if data_mb <= 64:  # <= 64MB: çº¯çº¿æ€§å…³ç³» y = a*x
            effective_bandwidth = a * gpu_factor * data_mb
        else:  # > 64MB: å¹³å°é˜¶æ®µ
            # å¹³å°å€¼åŸºäº64MBæ—¶çš„çº¿æ€§å€¼
            plateau_base = a * gpu_factor * 64
            effective_bandwidth = plateau_base * (0.95 + 0.1 * np.random.random())  # 95-105%éšæœºå˜åŒ–
        
        # æ·»åŠ å°é‡éšæœºå™ªå£°
        noise_factor = 1 + np.random.normal(0, 0.3)
        effective_bandwidth *= noise_factor
        
        return effective_bandwidth
    
    # ä¸ºæ¯ä¸ªGPUç”Ÿæˆæ•°æ®é›†
    datasets = {}
    
    for gpu_name, gpu_config in gpu_configs.items():
        print(f"ç”Ÿæˆ {gpu_name} æ•°æ®é›†...")
        gpu_data = []
        
        for algorithm in algorithms.keys():
            for i, data_size_mb in enumerate(data_sizes_mb):
                # æ£€æŸ¥GPUå†…å­˜é™åˆ¶
                data_bytes = mb_to_bytes(data_size_mb)
                if data_bytes > gpu_config['memory_size'] * 1024**3:
                    continue  # è·³è¿‡è¶…å‡ºGPUå†…å­˜çš„æ•°æ®å¤§å°
                
                throughput = calculate_roofline_performance(algorithm, data_size_mb, gpu_config)
                
                gpu_data.append({
                    'algorithm': algorithm,
                    'data_size_mb': data_size_mb,  # æ•°å€¼å½¢å¼
                    'data_size_label': data_size_labels[i],  # æ˜¾ç¤ºæ ‡ç­¾
                    'throughput': max(throughput, 0.01)  # ç¡®ä¿éè´Ÿå€¼
                })
        
        # ä¿å­˜æ•°æ®é›† (ä¿å­˜æ•°å€¼æ ¼å¼çš„data_size_mbç”¨äºç»˜å›¾)
        df = pd.DataFrame(gpu_data)
        # ä¸ºäº†å…¼å®¹æ€§ï¼ŒCSVä¸­åªä¿å­˜algorithm, data_size_mb, throughput
        csv_df = df[['algorithm', 'data_size_mb', 'throughput']].rename(columns={'data_size_mb': 'data_size'})
        filename = f"{gpu_name.lower()}_performance.csv"
        csv_df.to_csv(filename, index=False)
        datasets[gpu_name] = df
        
        print(f"  - {filename}: {len(gpu_data)} æ¡è®°å½•")
    
    print(f"\nå…±ç”Ÿæˆ {len(datasets)} ä¸ªGPUæ•°æ®é›†ï¼Œè¦†ç›– {len(algorithms)} ç§ç®—æ³•ç±»å‹")
    print(f"æ•°æ®è§„æ¨¡èŒƒå›´: {data_size_labels[0]} - {data_size_labels[-1]}")
    
    return datasets

def create_sample_datasets():
    """åˆ›å»ºç®€å•ç¤ºä¾‹æ•°æ®é›†ï¼ˆå‘åå…¼å®¹ï¼‰"""
    return create_comprehensive_datasets()


def main():
    parser = argparse.ArgumentParser(description='GPU Performance Comparison Tool')
    parser.add_argument('--csv-files', nargs='+',
                        help='CSV file paths')
    parser.add_argument('--labels', nargs='+',
                        help='Labels for each CSV file (e.g., GPU names)')
    parser.add_argument('--output', '-o', default='performance_comparison.html',
                        help='Output file path (default: performance_comparison.html)')
    parser.add_argument('--width', type=int, default=1200,
                        help='Chart width (default: 1200)')
    parser.add_argument('--height', type=int, default=800,
                        help='Chart height (default: 800)')
    parser.add_argument('--create-sample', action='store_true',
                        help='Create sample datasets and exit')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    if args.create_sample:
        create_sample_datasets()
        return
    
    # éªŒè¯å¿…éœ€å‚æ•°ï¼ˆä»…åœ¨æ²¡æœ‰åˆ›å»ºç¤ºä¾‹æ•°æ®æ—¶éœ€è¦ï¼‰
    if not args.create_sample and (not args.csv_files or not args.labels):
        print("é”™è¯¯: éœ€è¦æŒ‡å®š --csv-files å’Œ --labels å‚æ•°")
        print("ä½¿ç”¨ --help æŸ¥çœ‹å®Œæ•´å¸®åŠ©ä¿¡æ¯")
        print("æˆ–ä½¿ç”¨ --create-sample åˆ›å»ºç¤ºä¾‹æ•°æ®")
        sys.exit(1)
    
    # éªŒè¯å‚æ•°
    if len(args.csv_files) != len(args.labels):
        print("é”™è¯¯: CSVæ–‡ä»¶æ•°é‡ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…")
        sys.exit(1)
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    for csv_file in args.csv_files:
        if not Path(csv_file).exists():
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {csv_file}")
            sys.exit(1)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = PerformanceAnalyzer()
    
    # åŠ è½½æ•°æ®é›†
    for csv_file, label in zip(args.csv_files, args.labels):
        analyzer.load_dataset(csv_file, label)
    
    if not analyzer.datasets:
        print("é”™è¯¯: æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®é›†")
        sys.exit(1)
    
    # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    print("\næ­£åœ¨ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨...")
    analyzer.create_comparison_line_chart(
        save_path=args.output,
        width=args.width,
        height=args.height
    )
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    print("\n" + analyzer.generate_summary_report())


if __name__ == "__main__":
    main()
