#!/usr/bin/env python3
"""
GPUæ€§èƒ½æµ‹è¯•å¯¹æ¯”æ•°æ®ç»Ÿè®¡å›¾è¡¨ç”Ÿæˆå·¥å…· (Plotlyç‰ˆæœ¬)
æ”¯æŒå¤šä¸ªCSVæ–‡ä»¶è¾“å…¥ï¼Œå¯¹æ¯”ä¸åŒGPUçš„å¹¶è¡Œè®¡ç®—ç®—æ³•æ€§èƒ½
"""

import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
import numpy as np
import argparse
import sys
from pathlib import Path
from typing import Dict, List, Tuple, Optional

class PerformanceAnalyzer:
    def __init__(self):
        self.datasets = {}  # {label: dataframe}
    
    def _get_rgb_from_name(self, color_name):
        """å°†é¢œè‰²åç§°è½¬æ¢ä¸ºRGBå€¼"""
        color_map = {
            'red': '220, 38, 38',           # äº®çº¢
            'green': '34, 197, 94',         # ç¿ ç»¿  
            'blue': '59, 130, 246',         # äº®è“
            'orange': '249, 115, 22',       # äº®æ©™
            'purple': '168, 85, 247',       # äº®ç´«
            'brown': '161, 98, 7',          # æ£•è‰²
            'pink': '236, 72, 153',         # äº®ç²‰
            'gray': '107, 114, 128',        # ç°è‰²
            'olive': '132, 204, 22',        # æ©„æ¦„ç»¿
            'cyan': '6, 182, 212',          # é’è‰²
            'indigo': '99, 102, 241',       # é›è“
            'emerald': '16, 185, 129',      # ç¿¡ç¿ ç»¿
            'rose': '244, 63, 94',          # ç«ç‘°çº¢
            'amber': '245, 158, 11',        # ç¥ç€è‰²
            'teal': '20, 184, 166'          # è“ç»¿è‰²
        }
        return color_map.get(color_name, '0, 0, 0')  # é»˜è®¤é»‘è‰²
        
    def load_dataset(self, csv_path: str, label: str):
        """
        åŠ è½½CSVæ•°æ®é›†å¹¶æŒ‡å®šæ ‡ç­¾(å¦‚GPUåç§°)
        
        CSVæ ¼å¼è¦æ±‚:
        - algorithm: ç®—æ³•åç§° (å¦‚sort, reduce, scanç­‰)
        - data_size: æ•°æ®é‡è§„æ¨¡ (ä»¥MBä¸ºå•ä½çš„æ•°å€¼ï¼Œå¦‚1, 16, 1024)
        - throughput: ååé‡ (GB/s)
        """
        try:
            df = pd.read_csv(csv_path)
            
            # éªŒè¯å¿…éœ€çš„åˆ—
            required_columns = ['algorithm', 'data_size', 'throughput']
            missing_columns = [col for col in required_columns if col not in df.columns]
            if missing_columns:
                raise ValueError(f"CSVæ–‡ä»¶ {csv_path} ç¼ºå°‘å¿…éœ€çš„åˆ—: {missing_columns}")
            
            # ç¡®ä¿data_sizeæ˜¯æ•°å€¼ç±»å‹
            df['data_size'] = pd.to_numeric(df['data_size'], errors='coerce')
            
            # æ·»åŠ æ ‡ç­¾åˆ—
            df['gpu_label'] = label
            self.datasets[label] = df
            
            print(f"æˆåŠŸåŠ è½½æ•°æ®é›†: {label} ({len(df)} æ¡è®°å½•)")
            return df
            
        except Exception as e:
            print(f"åŠ è½½æ•°æ®é›†å¤±è´¥ {csv_path}: {e}")
            return None
    
    def get_combined_dataframe(self) -> pd.DataFrame:
        """åˆå¹¶æ‰€æœ‰æ•°æ®é›†"""
        if not self.datasets:
            return pd.DataFrame()
        
        combined_df = pd.concat(self.datasets.values(), ignore_index=True)
        return combined_df
    
    
    def calculate_percentage_differences(self, extreme_threshold=300):
        """
        è®¡ç®—ç›¸å¯¹äºç¬¬ä¸€ä¸ªGPUçš„æ€§èƒ½ç™¾åˆ†æ¯”å·®å¼‚
        
        Args:
            extreme_threshold: æç«¯æ•°æ®é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼çš„å·®å¼‚å°†è¢«æ ‡è®°ä¸ºæç«¯æ•°æ®
        
        Returns:
            tuple: (normal_data_df, extreme_data_list, anomaly_data_list) - æ­£å¸¸æ•°æ®ã€æç«¯æ•°æ®å’Œå¼‚å¸¸æ•°æ®
        """
        df = self.get_combined_dataframe()
        if df.empty or len(df['gpu_label'].unique()) <= 1:
            return None, [], []
        
        gpu_labels = df['gpu_label'].unique()
        if len(gpu_labels) < 2:
            return None, [], []
        
        # ä»¥ç¬¬ä¸€ä¸ªGPUä¸ºåŸºå‡†
        baseline_gpu = gpu_labels[0]
        comparison_gpus = gpu_labels[1:]
        
        percentage_data = []
        extreme_data = []
        anomaly_data = []
        
        # è·å–æ‰€æœ‰ç®—æ³•å’Œæ•°æ®å¤§å°çš„ç»„åˆ
        algorithms = df['algorithm'].unique()
        data_sizes = df['data_size'].unique()
        
        for algorithm in algorithms:
            for data_size in data_sizes:
                # è·å–åŸºå‡†æ€§èƒ½
                baseline_mask = (df['gpu_label'] == baseline_gpu) & \
                               (df['algorithm'] == algorithm) & \
                               (df['data_size'] == data_size)
                baseline_data = df[baseline_mask]
                
                if baseline_data.empty:
                    continue
                
                baseline_throughput = baseline_data['throughput'].iloc[0]
                
                # è®¡ç®—å…¶ä»–GPUçš„ç™¾åˆ†æ¯”å·®å¼‚
                for gpu in comparison_gpus:
                    comparison_mask = (df['gpu_label'] == gpu) & \
                                     (df['algorithm'] == algorithm) & \
                                     (df['data_size'] == data_size)
                    comparison_data = df[comparison_mask]
                    
                    if comparison_data.empty:
                        continue
                    
                    comparison_throughput = comparison_data['throughput'].iloc[0]
                    
                    # æ£€æŸ¥å¼‚å¸¸æ•°æ®
                    is_anomaly = False
                    anomaly_reason = ""
                    
                    # æ£€æŸ¥åŸºå‡†æ•°æ®å¼‚å¸¸
                    if (baseline_throughput <= 0 or 
                        np.isnan(baseline_throughput) or 
                        np.isinf(baseline_throughput)):
                        is_anomaly = True
                        anomaly_reason = f"å¼‚å¸¸åŸºå‡†å€¼: {baseline_throughput}"
                    
                    # æ£€æŸ¥å¯¹æ¯”æ•°æ®å¼‚å¸¸
                    elif (comparison_throughput <= 0 or 
                          np.isnan(comparison_throughput) or 
                          np.isinf(comparison_throughput)):
                        is_anomaly = True
                        anomaly_reason = f"å¼‚å¸¸å¯¹æ¯”å€¼: {comparison_throughput}"
                    
                    if is_anomaly:
                        # è®°å½•å¼‚å¸¸æ•°æ®
                        anomaly_data.append({
                            'algorithm': algorithm,
                            'data_size': data_size,
                            'gpu_label': gpu,
                            'baseline_throughput': baseline_throughput,
                            'comparison_throughput': comparison_throughput,
                            'reason': anomaly_reason
                        })
                        continue
                    
                    # è®¡ç®—ç™¾åˆ†æ¯”æ¯”å€¼ï¼Œ100%è¡¨ç¤ºæ€§èƒ½ç›¸ç­‰
                    percentage_diff = (comparison_throughput / baseline_throughput) * 100
                    
                    # æ£€æŸ¥è®¡ç®—ç»“æœæ˜¯å¦å¼‚å¸¸
                    if np.isnan(percentage_diff) or np.isinf(percentage_diff):
                        anomaly_data.append({
                            'algorithm': algorithm,
                            'data_size': data_size,
                            'gpu_label': gpu,
                            'baseline_throughput': baseline_throughput,
                            'comparison_throughput': comparison_throughput,
                            'reason': f"è®¡ç®—ç»“æœå¼‚å¸¸: {percentage_diff}"
                        })
                        continue
                    
                    data_point = {
                        'algorithm': algorithm,
                        'data_size': data_size,
                        'gpu_label': gpu,
                        'percentage_diff': percentage_diff,
                        'baseline_throughput': baseline_throughput,
                        'comparison_throughput': comparison_throughput
                    }
                    
                    # æ£€æŸ¥æ˜¯å¦ä¸ºæç«¯æ•°æ® (æ¯”å€¼è¶…è¿‡300%æˆ–ä½äº33.3%)
                    if percentage_diff > extreme_threshold or percentage_diff < (100 * 100 / extreme_threshold):
                        extreme_data.append(data_point)
                    else:
                        percentage_data.append(data_point)
        
        return pd.DataFrame(percentage_data), extreme_data, anomaly_data

    def create_comparison_line_chart(self, save_path: str = None, width: int = 1200, height: int = 800, reference_lines: list = None):
        """
        åˆ›å»ºå¤šGPUæ€§èƒ½å¯¹æ¯”æŠ˜çº¿å›¾å’Œç™¾åˆ†æ¯”å·®å¼‚å›¾
        åŒ…å«åŸå§‹æ€§èƒ½å›¾å’Œç›¸å¯¹äºç¬¬ä¸€ä¸ªGPUçš„ç™¾åˆ†æ¯”å·®å¼‚å›¾
        
        Args:
            reference_lines: å‚è€ƒçº¿åˆ—è¡¨ï¼Œé»˜è®¤[100.0]ã€‚å•ä¸ªå€¼è¡¨ç¤ºå…¨å±€å‚è€ƒçº¿ï¼Œå¤šä¸ªå€¼è¡¨ç¤ºæ¯ä¸ªå¯¹æ¯”ç»„çš„å‚è€ƒçº¿
        """
        df = self.get_combined_dataframe()
        
        if df.empty:
            print("æ²¡æœ‰æ•°æ®å¯ä»¥ç»˜åˆ¶")
            return None
        
        # å¤„ç†å‚è€ƒçº¿é»˜è®¤å€¼
        if reference_lines is None:
            reference_lines = [100.0]
        
        # è·å–GPUæ ‡ç­¾æ•°é‡
        gpu_labels = df['gpu_label'].unique()
        has_multiple_gpus = len(gpu_labels) > 1
        
        # å¦‚æœæœ‰å¤šä¸ªGPUï¼Œåˆ›å»ºå­å›¾ï¼›å¦åˆ™åªåˆ›å»ºå•ä¸ªå›¾è¡¨
        if has_multiple_gpus:
            # æ ¹æ®GPUæ•°é‡å†³å®šå­å›¾å¸ƒå±€
            comparison_gpus = gpu_labels[1:]
            num_comparisons = len(comparison_gpus)
            
            # åŠ¨æ€å¸ƒå±€ï¼šæ ¹æ®å¯¹æ¯”ç»„æ•°é‡åˆ›å»ºå­å›¾
            # ç¬¬ä¸€è¡Œï¼šåŸå§‹æ€§èƒ½å¯¹æ¯”
            # ç¬¬äºŒè¡Œï¼šç™¾åˆ†æ¯”å·®å¼‚å¯¹æ¯”
            # ç¬¬ä¸‰è¡Œå¼€å§‹ï¼šæ¯ä¸ªå¯¹æ¯”ç»„ä¸€ä¸ªç›´æ–¹å›¾å­å›¾
            
            total_rows = 2 + num_comparisons  # å‰ä¸¤è¡Œ + æ¯ä¸ªå¯¹æ¯”ç»„çš„ç›´æ–¹å›¾
            comparison_cols = min(num_comparisons, 3)  # æœ€å¤š3åˆ—ç›´æ–¹å›¾
            comparison_rows = (num_comparisons + comparison_cols - 1) // comparison_cols  # è®¡ç®—éœ€è¦çš„è¡Œæ•°
            
            # åˆ›å»ºå­å›¾æ ‡é¢˜
            subplot_titles = [
                'åŸå§‹æ€§èƒ½å¯¹æ¯”',
                f'ç›¸å¯¹äº {gpu_labels[0]} çš„æ€§èƒ½ç™¾åˆ†æ¯”å·®å¼‚'
            ]
            
            # ä¸ºæ¯ä¸ªå¯¹æ¯”ç»„æ·»åŠ ç›´æ–¹å›¾æ ‡é¢˜
            for i, gpu in enumerate(comparison_gpus):
                subplot_titles.append(f'{gpu} vs {gpu_labels[0]} - å·®å¼‚åˆ†å¸ƒç›´æ–¹å›¾')
            
            # è®¡ç®—å¸ƒå±€è§„æ ¼
            if num_comparisons == 1:
                # å•å¯¹æ¯”ï¼š3è¡Œ1åˆ—
                fig = make_subplots(
                    rows=3, cols=1,
                    subplot_titles=subplot_titles,
                    vertical_spacing=0.12,
                    specs=[[{"secondary_y": False}], [{"secondary_y": False}], [{"secondary_y": False}]],
                    row_heights=[0.35, 0.35, 0.3]
                )
                total_height = int(height * 2.2)
            elif num_comparisons == 2:
                # åŒå¯¹æ¯”ï¼š3è¡Œ2åˆ—ï¼ˆç¬¬ä¸‰è¡Œæ”¾2ä¸ªç›´æ–¹å›¾ï¼‰
                fig = make_subplots(
                    rows=3, cols=2,
                    subplot_titles=subplot_titles,
                    vertical_spacing=0.12,
                    horizontal_spacing=0.1,
                    specs=[[{"secondary_y": False, "colspan": 2}, None], 
                           [{"secondary_y": False, "colspan": 2}, None],
                           [{"secondary_y": False}, {"secondary_y": False}]],
                    row_heights=[0.35, 0.35, 0.3]
                )
                total_height = int(height * 2.2)
                width = int(width * 1.3)
            else:
                # å¤šå¯¹æ¯”ï¼šé‡‡ç”¨æ›´çµæ´»çš„å¸ƒå±€
                cols = min(num_comparisons, 3)
                histogram_rows = (num_comparisons + cols - 1) // cols
                total_rows = 2 + histogram_rows
                
                # æ„å»ºspecs
                specs = []
                # å‰ä¸¤è¡Œè·¨æ‰€æœ‰åˆ—
                specs.append([{"secondary_y": False, "colspan": cols}] + [None] * (cols - 1))
                specs.append([{"secondary_y": False, "colspan": cols}] + [None] * (cols - 1))
                
                # ç›´æ–¹å›¾è¡Œ
                for row in range(histogram_rows):
                    row_specs = []
                    for col in range(cols):
                        idx = row * cols + col
                        if idx < num_comparisons:
                            row_specs.append({"secondary_y": False})
                        else:
                            row_specs.append(None)
                    specs.append(row_specs)
                
                # è®¡ç®—è¡Œé«˜
                row_heights = [0.25, 0.25] + [0.5 / histogram_rows] * histogram_rows
                
                fig = make_subplots(
                    rows=total_rows, cols=cols,
                    subplot_titles=subplot_titles,
                    vertical_spacing=0.08,
                    horizontal_spacing=0.08,
                    specs=specs,
                    row_heights=row_heights
                )
                total_height = int(height * (1.5 + 0.5 * histogram_rows))
                width = int(width * 1.4)
        else:
            # åªæœ‰ä¸€ä¸ªGPUæ—¶ï¼Œåˆ›å»ºå•ä¸ªå›¾è¡¨
            fig = go.Figure()
            total_height = height
        
        # è·å–å”¯ä¸€çš„ç®—æ³•å’ŒGPUæ ‡ç­¾
        algorithms = df['algorithm'].unique()
        
        # é¢œè‰²å’Œçº¿å‹é…ç½®
        colors = px.colors.qualitative.Set1
        line_styles = ['solid', 'dash', 'dot', 'dashdot']
        
        # åˆ›å»ºè‡ªå®šä¹‰hover textæ˜¾ç¤ºæ•°æ®å¤§å°æ ‡ç­¾çš„å‡½æ•°
        def mb_to_label(mb_value):
            if mb_value < 1:
                simplified = f"{int(mb_value * 1024)}KB"
            elif mb_value < 1024:
                simplified = f"{mb_value:.1f}MB" if mb_value != int(mb_value) else f"{int(mb_value)}MB"
            else:
                simplified = f"{mb_value/1024:.1f}GB" if (mb_value/1024) != int(mb_value/1024) else f"{int(mb_value/1024)}GB"
            return f"{mb_value:.1f}MB ({simplified})"
        
        # æ·»åŠ åŸå§‹æ€§èƒ½æ•°æ®åˆ°ç¬¬ä¸€ä¸ªå­å›¾ï¼ˆæˆ–å”¯ä¸€çš„å›¾è¡¨ï¼‰
        for i, gpu in enumerate(gpu_labels):
            gpu_data = df[df['gpu_label'] == gpu]
            
            for j, algorithm in enumerate(algorithms):
                algo_data = gpu_data[gpu_data['algorithm'] == algorithm]
                
                if algo_data.empty:
                    continue
                
                # æŒ‰æ•°æ®é‡æ’åº
                algo_data = algo_data.sort_values('data_size')
                
                # åˆ›å»ºè½¨è¿¹
                trace_name = f"{gpu} - {algorithm}"
                
                hover_labels = [mb_to_label(x) for x in algo_data['data_size']]
                
                scatter_trace = go.Scatter(
                    x=algo_data['data_size'],
                    y=algo_data['throughput'],
                    mode='lines+markers',
                    name=trace_name,
                    line=dict(
                        color=colors[j % len(colors)],
                        dash=line_styles[i % len(line_styles)],
                        width=2
                    ),
                    marker=dict(
                        size=8,
                        symbol=['circle', 'square', 'diamond', 'triangle-up'][i % 4]
                    ),
                    customdata=hover_labels,
                    hovertemplate=(
                        f"<b>{trace_name}</b><br>"
                        "Data Size: %{customdata}<br>"
                        "Throughput: %{y:.2f} GB/s<br>"
                        "<extra></extra>"
                    )
                )
                
                if has_multiple_gpus:
                    fig.add_trace(scatter_trace, row=1, col=1)
                else:
                    fig.add_trace(scatter_trace)
        
        # å¦‚æœæœ‰å¤šä¸ªGPUï¼Œæ·»åŠ ç™¾åˆ†æ¯”å·®å¼‚å›¾åˆ°ç¬¬äºŒä¸ªå­å›¾
        if has_multiple_gpus:
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            
            if percentage_df is not None and not percentage_df.empty:
                baseline_gpu = gpu_labels[0]
                comparison_gpus = gpu_labels[1:]
                
                colors_comparison = px.colors.qualitative.Set2
                
                for i, gpu in enumerate(comparison_gpus):
                    gpu_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    
                    for j, algorithm in enumerate(algorithms):
                        algo_data = gpu_data[gpu_data['algorithm'] == algorithm]
                        
                        if algo_data.empty:
                            continue
                        
                        # æŒ‰æ•°æ®é‡æ’åº
                        algo_data = algo_data.sort_values('data_size')
                        
                        # åˆ›å»ºç™¾åˆ†æ¯”å·®å¼‚è½¨è¿¹
                        trace_name = f"{gpu} vs {baseline_gpu} - {algorithm}"
                        
                        hover_labels = [mb_to_label(x) for x in algo_data['data_size']]
                        
                        percentage_trace = go.Scatter(
                            x=algo_data['data_size'],
                            y=algo_data['percentage_diff'],
                            mode='lines+markers',
                            name=f"{gpu} vs {baseline_gpu} - {algorithm}",
                            line=dict(
                                color=colors_comparison[j % len(colors_comparison)],
                                dash=line_styles[i % len(line_styles)],
                                width=2
                            ),
                            marker=dict(
                                size=8,
                                symbol=['circle', 'square', 'diamond', 'triangle-up'][i % 4]
                            ),
                            customdata=hover_labels,
                            hovertemplate=(
                                f"<b>{gpu} vs {baseline_gpu} - {algorithm}</b><br>"
                                "Data Size: %{customdata}<br>"
                                "Performance Ratio: %{y:.1f}%<br>"
                                "Baseline: %{customdata[0]:.2f} GB/s<br>"
                                "Comparison: %{customdata[1]:.2f} GB/s<br>"
                                "<extra></extra>"
                            )
                        )
                        
                        # æ›´æ–°hoveræ•°æ®ä»¥åŒ…å«ååé‡ä¿¡æ¯
                        hover_data = []
                        for _, row in algo_data.iterrows():
                            hover_data.append([
                                mb_to_label(row['data_size']),
                                row['baseline_throughput'],
                                row['comparison_throughput']
                            ])
                        
                        percentage_trace.customdata = hover_data
                        
                        fig.add_trace(percentage_trace, row=2, col=1)
        
        # æ›´æ–°å¸ƒå±€
        if has_multiple_gpus:
            # å¤šGPUæ—¶çš„å¸ƒå±€è®¾ç½®
            fig.update_layout(
                title=dict(
                    text="GPU Performance Comparison - Original and Percentage Differences",
                    x=0.5,
                    font=dict(size=20)
                ),
                width=width,
                height=total_height,
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white',
                # è®¾ç½®ç›´æ–¹å›¾æŸ±é—´è·å’Œç»„é—´è·
                bargap=0.2,      # åŒç»„å†…æŸ±é—´è·
                bargroupgap=0.1  # ä¸åŒç»„é—´è·
            )
            
            # è·å–å®é™…æ•°æ®è§„æ¨¡å¹¶ç”Ÿæˆåˆ»åº¦æ ‡ç­¾
            actual_data_sizes = sorted(df['data_size'].unique())
            
            # ç”Ÿæˆåˆ»åº¦æ ‡ç­¾å‡½æ•°
            def generate_tick_label(mb_value):
                if mb_value < 1:
                    return f"{int(mb_value * 1024)}KB"
                elif mb_value < 1024:
                    if mb_value == int(mb_value):
                        return f"{int(mb_value)}MB"
                    else:
                        return f"{mb_value:.1f}MB"
                else:
                    gb_value = mb_value / 1024
                    if gb_value == int(gb_value):
                        return f"{int(gb_value)}GB"
                    else:
                        return f"{gb_value:.1f}GB"
            
            # é€‰æ‹©åˆé€‚çš„åˆ»åº¦ç‚¹ - æ˜¾ç¤ºæ‰€æœ‰é‡è¦çš„æ•°æ®ç‚¹ä»¥ä¾¿ç”¨æˆ·æŸ¥çœ‹è¯¦ç»†æ•°æ®
            # ç”±äºæˆ‘ä»¬æœ‰å¢å¼ºçš„æ•°æ®é‡‡æ ·ï¼Œç›´æ¥æ˜¾ç¤ºæ‰€æœ‰æ•°æ®ç‚¹ä½œä¸ºåˆ»åº¦
            # è¿™æ ·ç”¨æˆ·å¯ä»¥çœ‹åˆ°æ‰€æœ‰çš„1.2MB, 1.6MB, 1.8MBç­‰è¯¦ç»†æ•°æ®ç‚¹
            
            if len(actual_data_sizes) <= 30:
                # æ•°æ®ç‚¹ä¸å¤ªå¤šï¼Œæ˜¾ç¤ºæ‰€æœ‰æ•°æ®ç‚¹
                selected_tickvals = actual_data_sizes
                selected_ticktext = [generate_tick_label(val) for val in selected_tickvals]
            else:
                # æ•°æ®ç‚¹å¾ˆå¤šæ—¶ï¼Œæ™ºèƒ½é€‰æ‹©æ˜¾ç¤º
                tick_indices = []
                
                # 1. æ·»åŠ åˆæœŸå¯†é›†é‡‡æ ·çš„é‡è¦ç‚¹ï¼ˆ1-10MBèŒƒå›´ï¼‰
                for i, size in enumerate(actual_data_sizes):
                    if size <= 10:  # 1-10MBèŒƒå›´æ˜¾ç¤ºæ›´å¤šåˆ»åº¦
                        tick_indices.append(i)
                    elif size <= 100 and i % 2 == 0:  # 10-100MBèŒƒå›´éš”ç‚¹æ˜¾ç¤º
                        tick_indices.append(i)
                    elif size <= 1024 and i % 4 == 0:  # 100MB-1GBèŒƒå›´ç¨€ç–æ˜¾ç¤º
                        tick_indices.append(i)
                    elif i % 6 == 0:  # 1GBä»¥ä¸Šæ›´ç¨€ç–æ˜¾ç¤º
                        tick_indices.append(i)
                
                # 2. ç¡®ä¿åŒ…å«é‡è¦çš„é‡Œç¨‹ç¢‘ç‚¹
                milestone_values = [1, 1.2, 1.6, 1.8, 2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096]
                for milestone in milestone_values:
                    if milestone in actual_data_sizes:
                        milestone_idx = actual_data_sizes.index(milestone)
                        if milestone_idx not in tick_indices:
                            tick_indices.append(milestone_idx)
                
                # 3. æ€»æ˜¯åŒ…å«é¦–å°¾ç‚¹
                if 0 not in tick_indices:
                    tick_indices.append(0)
                if len(actual_data_sizes) - 1 not in tick_indices:
                    tick_indices.append(len(actual_data_sizes) - 1)
                
                tick_indices = sorted(list(set(tick_indices)))
                selected_tickvals = [actual_data_sizes[i] for i in tick_indices]
                selected_ticktext = [generate_tick_label(val) for val in selected_tickvals]
            
            # æ›´æ–°ç¬¬ä¸€ä¸ªå­å›¾çš„è½´æ ‡ç­¾
            fig.update_xaxes(
                title=dict(text="Data Size (MB)", font=dict(size=14)),
                type="log",
                tickmode='array',
                tickvals=selected_tickvals,
                ticktext=selected_ticktext,
                row=1, col=1
            )
            fig.update_yaxes(
                title=dict(text="Throughput (GB/s)", font=dict(size=14)),
                type="log",
                row=1, col=1
            )
            
            # æ›´æ–°ç¬¬äºŒä¸ªå­å›¾çš„è½´æ ‡ç­¾
            fig.update_xaxes(
                title=dict(text="Data Size (MB)", font=dict(size=14)),
                type="log",
                tickmode='array',
                tickvals=selected_tickvals,
                ticktext=selected_ticktext,
                row=2, col=1
            )
            fig.update_yaxes(
                title=dict(text="Performance Ratio (%)", font=dict(size=14)),
                row=2, col=1
            )
            
            # ä¸ºæ¯ä¸ªç›´æ–¹å›¾å­å›¾æ·»åŠ ç½‘æ ¼
            for i, gpu in enumerate(comparison_gpus):
                if num_comparisons == 1:
                    hist_row, hist_col = 3, 1
                elif num_comparisons == 2:
                    hist_row, hist_col = 3, i + 1
                else:
                    cols = min(num_comparisons, 3)
                    hist_row = 3 + i // cols
                    hist_col = (i % cols) + 1
                
                fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=hist_row, col=hist_col)
                fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=hist_row, col=hist_col)
            
            # æ·»åŠ åŸºå‡†çº¿(100%)åˆ°ç™¾åˆ†æ¯”å›¾
            fig.add_hline(y=100, line_dash="dash", line_color="black", line_width=1, row=2, col=1)
            
            # æ·»åŠ ç”¨æˆ·æŒ‡å®šçš„å‚è€ƒçº¿åˆ°ç™¾åˆ†æ¯”å›¾
            if reference_lines:
                for ref_line in reference_lines:
                    if ref_line != 100:  # é¿å…é‡å¤æ·»åŠ 100%çº¿
                        fig.add_hline(
                            y=ref_line, 
                            line_dash="solid", 
                            line_color="blue", 
                            line_width=2,
                            annotation_text=f"å‚è€ƒçº¿: {ref_line}%",
                            annotation_position="right",
                            row=2, col=1
                        )
            
            # ä¸ºæ¯ä¸ªå¯¹æ¯”ç»„åˆ›å»ºç‹¬ç«‹çš„ç›´æ–¹å›¾å­å›¾
            if percentage_df is not None and not percentage_df.empty:
                # åˆ›å»ºè‡ªå®šä¹‰hoveræ–‡æœ¬æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
                def mb_to_label(mb_value):
                    if mb_value < 1:
                        return f"{int(mb_value * 1024)}KB"
                    elif mb_value < 1024:
                        return f"{int(mb_value)}MB"
                    else:
                        return f"{int(mb_value / 1024)}GB"
                
                comparison_gpus = gpu_labels[1:]
                
                # ä¸ºæ¯ä¸ªå¯¹æ¯”ç»„åˆ›å»ºç‹¬ç«‹çš„ç›´æ–¹å›¾å’Œæ•£ç‚¹å›¾
                for i, gpu in enumerate(comparison_gpus):
                    gpu_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    
                    if gpu_data.empty:
                        continue
                    
                    # ç¡®å®šå­å›¾ä½ç½®
                    if num_comparisons == 1:
                        hist_row, hist_col = 3, 1
                    elif num_comparisons == 2:
                        hist_row, hist_col = 3, i + 1
                    else:
                        # å¤šå¯¹æ¯”å¸ƒå±€
                        cols = min(num_comparisons, 3)
                        hist_row = 3 + i // cols
                        hist_col = (i % cols) + 1
                    
                    # 1. æ·»åŠ å¤§ç›´æ–¹å›¾æ˜¾ç¤ºæ•´ä½“åˆ†å¸ƒï¼ˆèƒŒæ™¯ï¼‰
                    histogram_trace = go.Histogram(
                        x=gpu_data['percentage_diff'],
                        nbinsx=20,
                        name=f'{gpu} åˆ†å¸ƒ',
                        opacity=0.3,  # é™ä½é€æ˜åº¦ä½œä¸ºèƒŒæ™¯
                        marker=dict(
                            color='rgba(30, 144, 255, 0.3)',
                            line=dict(color='rgba(30, 144, 255, 0.8)', width=1)
                        ),
                        showlegend=True,
                        hovertemplate=(
                            f"<b>{gpu} vs {gpu_labels[0]} åˆ†å¸ƒ</b><br>"
                            "æ€§èƒ½æ¯”å€¼èŒƒå›´: %{x}<br>"
                            "æ•°æ®ç‚¹æ•°é‡: %{y}<br>"
                            "<extra></extra>"
                        )
                    )
                    fig.add_trace(histogram_trace, row=hist_row, col=hist_col)
                    
                    # 2. è®¡ç®—ç›´æ–¹å›¾çš„æŸ±ä½“åˆ†å¸ƒï¼Œç”¨äºæ•£ç‚¹çš„å‚ç›´å®šä½
                    
                    # è®¡ç®—ç›´æ–¹å›¾çš„binså’Œcounts
                    percentage_values = gpu_data['percentage_diff'].values
                    hist_counts, bin_edges = np.histogram(percentage_values, bins=20)
                    bin_width = bin_edges[1] - bin_edges[0]
                    
                    # æŒ‰ç®—æ³•åˆ†ç»„ï¼Œå°†ç›¸åŒç®—æ³•çš„æ•°æ®ç‚¹æ”¾åœ¨æ¥è¿‘ä½ç½®
                    # 1. é¦–å…ˆå°†æ•°æ®æŒ‰binåˆ†ç»„
                    bins_data = {}
                    for _, row in gpu_data.iterrows():
                        x_value = row['percentage_diff']
                        bin_index = min(int((x_value - bin_edges[0]) / bin_width), len(hist_counts) - 1)
                        bin_index = max(0, bin_index)
                        
                        if bin_index not in bins_data:
                            bins_data[bin_index] = []
                        bins_data[bin_index].append(row)
                    
                    # 2. ä¸ºæ¯ä¸ªbinå†…çš„æ•°æ®æŒ‰ç®—æ³•åˆ†ç»„å¹¶åˆ†é…Yåæ ‡
                    scatter_points = []
                    for bin_index, bin_rows in bins_data.items():
                        bin_height = hist_counts[bin_index]
                        if bin_height == 0:
                            bin_height = 1  # æœ€å°é«˜åº¦
                        
                        # æŒ‰ç®—æ³•åˆ†ç»„
                        algo_groups = {}
                        for row in bin_rows:
                            algo = row['algorithm']
                            if algo not in algo_groups:
                                algo_groups[algo] = []
                            algo_groups[algo].append(row)
                        
                        # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…Yè½´å±‚çº§
                        algorithms = sorted(algo_groups.keys())  # æŒ‰å­—æ¯åºæ’åºä¿æŒä¸€è‡´æ€§
                        num_algorithms = len(algorithms)
                        
                        for algo_idx, algorithm in enumerate(algorithms):
                            algo_data = algo_groups[algorithm]
                            
                            # è®¡ç®—è¯¥ç®—æ³•åœ¨binä¸­çš„Yè½´èŒƒå›´
                            y_layer_start = (bin_height / num_algorithms) * algo_idx
                            y_layer_end = (bin_height / num_algorithms) * (algo_idx + 1)
                            
                            # åœ¨ç®—æ³•å±‚å†…æŒ‰æ•°æ®é‡æ’åº
                            algo_data.sort(key=lambda x: x['data_size'])
                            
                            # ä¸ºç®—æ³•å†…çš„æ¯ä¸ªæ•°æ®ç‚¹åˆ†é…Yåæ ‡
                            for data_idx, row in enumerate(algo_data):
                                x_value = row['percentage_diff']
                                
                                # åœ¨ç®—æ³•å±‚å†…å‡åŒ€åˆ†å¸ƒ
                                if len(algo_data) > 1:
                                    y_ratio = data_idx / (len(algo_data) - 1)
                                else:
                                    y_ratio = 0.5  # å•ä¸ªæ•°æ®ç‚¹å±…ä¸­
                                
                                # åœ¨ç®—æ³•å±‚èŒƒå›´å†…åˆ†å¸ƒï¼Œç•™å‡º10%è¾¹ç•Œ
                                layer_height = y_layer_end - y_layer_start
                                y_value = y_layer_start + layer_height * (0.1 + y_ratio * 0.8)
                                
                                # è®¡ç®—å½“å‰binçš„Xè½´è¾¹ç•Œ
                                bin_left = bin_edges[bin_index]
                                bin_right = bin_edges[bin_index + 1] if bin_index + 1 < len(bin_edges) else bin_edges[-1]
                                
                                # ç¡®ä¿Xè½´æŠ–åŠ¨ä¸è¶…å‡ºbinè¾¹ç•Œ
                                max_x_jitter = min(
                                    x_value - bin_left,      # è·å·¦è¾¹ç•Œçš„è·ç¦»
                                    bin_right - x_value,     # è·å³è¾¹ç•Œçš„è·ç¦»
                                    bin_width * 0.3          # æœ€å¤§æŠ–åŠ¨èŒƒå›´
                                ) * 0.8  # ç•™å‡º20%çš„å®‰å…¨è¾¹ç•Œ
                                
                                # Yè½´æŠ–åŠ¨ç¡®ä¿åœ¨ç®—æ³•å±‚å†…
                                y_jitter = np.random.uniform(-layer_height * 0.03, layer_height * 0.03)
                                x_jitter = np.random.uniform(-max_x_jitter, max_x_jitter)
                                
                                final_x = x_value + x_jitter
                                final_y = y_value + y_jitter
                                
                                # åŒé‡æ£€æŸ¥ï¼šç¡®ä¿æ•£ç‚¹åœ¨æ­£ç¡®çš„è¾¹ç•Œå†…
                                final_x = max(bin_left + bin_width * 0.05, min(bin_right - bin_width * 0.05, final_x))
                                final_y = max(y_layer_start + layer_height * 0.02, min(y_layer_end - layer_height * 0.02, final_y))
                                
                                scatter_points.append({
                                    'x': final_x,
                                    'y': final_y,  # ä¸å†å¼ºåˆ¶æœ€å°å€¼ï¼Œç¡®ä¿åœ¨ç›´æ–¹å›¾å†…
                                    'algorithm': row['algorithm'],
                                    'data_size': mb_to_label(row['data_size']),
                                    'baseline_throughput': row['baseline_throughput'],
                                    'comparison_throughput': row['comparison_throughput'],
                                    'percentage_diff': row['percentage_diff']  # ä¿æŒåŸå§‹å€¼ç”¨äºhover
                                })
                    
                    if scatter_points:
                        scatter_df = pd.DataFrame(scatter_points)
                        
                        # æ ¹æ®ç®—æ³•è®¾ç½®ä¸åŒçš„é¢œè‰²å’Œå½¢çŠ¶
                        algorithms = scatter_df['algorithm'].unique()
                        algorithm_colors = {}
                        algorithm_symbols = {}
                        
                        # ä¸ºæ¯ä¸ªç®—æ³•åˆ†é…é¢œè‰²å’Œç¬¦å· - ä½¿ç”¨æ›´ä¸°å¯Œçš„è°ƒè‰²æ¿
                        available_colors = ['red', 'green', 'blue', 'orange', 'purple', 'brown', 'pink', 'olive', 'cyan', 'indigo', 'emerald', 'rose', 'amber', 'teal', 'gray']
                        available_symbols = ['circle', 'square', 'diamond', 'cross', 'triangle-up', 'triangle-down', 'star', 'hexagon', 'pentagon', 'x']
                        
                        for j, algo in enumerate(algorithms):
                            algorithm_colors[algo] = available_colors[j % len(available_colors)]
                            algorithm_symbols[algo] = available_symbols[j % len(available_symbols)]
                        
                        # ç»Ÿä¸€å¤„ç†æ‰€æœ‰ç®—æ³•çš„å°æ–¹å—ï¼Œç¡®ä¿åŒä¸€binå†…ä¸åŒç®—æ³•ç”¨ä¸åŒé¢œè‰²å †å 
                        # 1. æŒ‰binåˆ†ç»„æ‰€æœ‰æ•°æ®ç‚¹
                        bin_groups = {}
                        for _, row in scatter_df.iterrows():
                            x_value = row['x']
                            bin_index = min(int((x_value - bin_edges[0]) / bin_width), len(hist_counts) - 1)
                            bin_index = max(0, bin_index)
                            
                            if bin_index not in bin_groups:
                                bin_groups[bin_index] = []
                            bin_groups[bin_index].append(row)
                        
                        # 2. ä¸ºæ¯ä¸ªbinåˆ›å»ºå †å çš„å°æ–¹å—ï¼Œä¸åŒç®—æ³•ç”¨ä¸åŒé¢œè‰²
                        bar_x = []
                        bar_y = []
                        bar_base = []
                        bar_customdata = []
                        bar_colors_list = []
                        
                        for bin_index, bin_data_points in bin_groups.items():
                            bin_height = hist_counts[bin_index]
                            if bin_height == 0 or len(bin_data_points) == 0:
                                continue
                            
                            # æ¯ä¸ªå°æ–¹å—çš„é«˜åº¦ = binæ€»é«˜åº¦ / è¯¥binå†…çš„æ•°æ®ç‚¹æ•°é‡
                            small_block_height = bin_height / len(bin_data_points)
                            
                            # binçš„Xè½´ä¸­å¿ƒä½ç½®
                            bin_center = bin_edges[bin_index] + bin_width / 2
                            
                            # æŒ‰ç®—æ³•åˆ†ç»„åå †å ï¼ˆç¡®ä¿é¢œè‰²ä¸€è‡´æ€§ï¼‰
                            bin_data_points = sorted(bin_data_points, key=lambda x: x['algorithm'])
                            
                            # ä»åº•éƒ¨å¼€å§‹å †å 
                            for block_idx, data_point in enumerate(bin_data_points):
                                bar_x.append(bin_center)
                                bar_y.append(small_block_height)
                                bar_base.append(block_idx * small_block_height)  # å †å ä½ç½®
                                
                                # ä¿å­˜hoveræ•°æ®
                                bar_customdata.append([
                                    data_point['algorithm'],
                                    data_point['data_size'],
                                    data_point['baseline_throughput'],
                                    data_point['comparison_throughput'],
                                    data_point['percentage_diff']
                                ])
                                
                                # é¢œè‰²ï¼ˆåŸºäºç®—æ³•ï¼‰- ç¡®ä¿ç›¸åŒç®—æ³•ä½¿ç”¨ç›¸åŒé¢œè‰²
                                base_color = algorithm_colors[data_point['algorithm']]
                                alpha = 0.9
                                bar_colors_list.append(f'rgba({self._get_rgb_from_name(base_color)}, {alpha})')
                        
                        # 3. åˆ›å»ºç»Ÿä¸€çš„å°æ–¹å—trace
                        if bar_x:  # åªæœ‰å½“æœ‰æ•°æ®æ—¶æ‰æ·»åŠ trace
                            bar_trace = go.Bar(
                                x=bar_x,
                                y=bar_y,
                                base=bar_base,
                                width=bin_width * 0.8,  # å°æ–¹å—å®½åº¦ä¸binå®½åº¦ç›¸åŒ
                                name=f'æ•°æ®ç‚¹ ({gpu})',
                                marker=dict(
                                    color=bar_colors_list,
                                    line=dict(color='white', width=1),
                                    opacity=0.9
                                ),
                                customdata=bar_customdata,
                                hovertemplate=(
                                    f"<b>{gpu} vs {gpu_labels[0]}</b><br>"
                                    "ç®—æ³•: %{customdata[0]}<br>"
                                    "æ•°æ®é‡: %{customdata[1]}<br>"
                                    "æ€§èƒ½æ¯”å€¼: %{customdata[4]:.1f}%<br>"
                                    f"{gpu_labels[0]}: %{{customdata[2]:.2f}} GB/s<br>"
                                    f"{gpu}: %{{customdata[3]:.2f}} GB/s<br>"
                                    "<extra></extra>"
                                ),
                                showlegend=True
                            )
                            fig.add_trace(bar_trace, row=hist_row, col=hist_col)
                    
                    # 3. é¦–å…ˆæ·»åŠ ç”¨æˆ·æŒ‡å®šçš„å‚è€ƒçº¿
                    if reference_lines:
                        # è·å–å½“å‰å¯¹æ¯”ç»„çš„å‚è€ƒçº¿
                        if len(reference_lines) == 1:
                            current_ref_line = reference_lines[0]
                        else:
                            current_ref_line = reference_lines[i] if i < len(reference_lines) else reference_lines[-1]
                        
                        # æ·»åŠ ç”¨æˆ·æŒ‡å®šçš„å‚è€ƒçº¿
                        fig.add_vline(
                            x=current_ref_line, 
                            line_dash="solid", 
                            line_color="blue", 
                            line_width=3,
                            annotation_text=f"å‚è€ƒçº¿: {current_ref_line}%",
                            annotation_position="top",
                            annotation=dict(
                                font=dict(size=12, color="blue"),
                                bgcolor="rgba(255,255,255,0.9)",
                                bordercolor="blue",
                                borderwidth=2
                            ),
                            row=hist_row, col=hist_col
                        )
                    
                    # 4. æ·»åŠ ç»Ÿè®¡å‚è€ƒçº¿ï¼Œæ™ºèƒ½é¿å…æ ‡æ³¨é‡å 
                    mean_diff = gpu_data['percentage_diff'].mean()
                    median_diff = gpu_data['percentage_diff'].median()
                    
                    # è®¡ç®—æ•°æ®èŒƒå›´ç”¨äºæ™ºèƒ½å®šä½æ ‡æ³¨
                    data_min = gpu_data['percentage_diff'].min()
                    data_max = gpu_data['percentage_diff'].max()
                    data_range = data_max - data_min
                    
                    # æ™ºèƒ½é€‰æ‹©æ ‡æ³¨ä½ç½®ï¼Œé¿å…é‡å å’Œä¸æ ‡é¢˜å†²çª  
                    # å¦‚æœå‡å€¼å’Œä¸­ä½æ•°å¾ˆæ¥è¿‘ï¼Œé”™å¼€æ˜¾ç¤ºä½ç½®
                    mean_median_gap = abs(mean_diff - median_diff)
                    
                    if mean_median_gap < data_range * 0.1:  # å·®è·å°äºæ•°æ®èŒƒå›´çš„10%
                        # å·®è·è¾ƒå°æ—¶ï¼Œä¸€ä¸ªåœ¨ä¸Šä¸€ä¸ªåœ¨ä¸‹ï¼Œå¹¶ç¨å¾®åç§»
                        mean_position = "top right" if mean_diff > median_diff else "top left"
                        median_position = "bottom left" if mean_diff > median_diff else "bottom right"
                    else:
                        # å·®è·è¾ƒå¤§æ—¶ï¼Œéƒ½å¯ä»¥åœ¨ä¸Šæ–¹ï¼Œä½†å·¦å³åˆ†å¼€
                        mean_position = "top left"
                        median_position = "top right"
                    
                    # æ·»åŠ å‡å€¼çº¿
                    fig.add_vline(
                        x=mean_diff, 
                        line_dash="dash", 
                        line_color="red", 
                        annotation_text=f"å‡å€¼: {mean_diff:.1f}%", 
                        annotation_position=mean_position,
                        annotation=dict(
                            font=dict(size=10, color="red"),
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor="red",
                            borderwidth=1
                        ),
                        row=hist_row, col=hist_col
                    )
                    
                    # æ·»åŠ ä¸­ä½æ•°çº¿
                    fig.add_vline(
                        x=median_diff, 
                        line_dash="dot", 
                        line_color="green", 
                        annotation_text=f"ä¸­ä½æ•°: {median_diff:.1f}%", 
                        annotation_position=median_position,
                        annotation=dict(
                            font=dict(size=10, color="green"),
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor="green",  
                            borderwidth=1
                        ),
                        row=hist_row, col=hist_col
                    )
                    
                    # æ·»åŠ åŸºå‡†çº¿(100%)
                    fig.add_vline(
                        x=100, 
                        line_dash="solid", 
                        line_color="black", 
                        line_width=2,
                        annotation_text="åŸºå‡†çº¿(100%)",
                        annotation_position="bottom",
                        annotation=dict(
                            font=dict(size=9, color="black"),
                            bgcolor="rgba(255,255,255,0.8)",
                            bordercolor="black",
                            borderwidth=1
                        ),
                        row=hist_row, col=hist_col
                    )
                    
                    # æ›´æ–°ç›´æ–¹å›¾å­å›¾çš„è½´æ ‡ç­¾
                    fig.update_xaxes(
                        title_text="æ€§èƒ½æ¯”å€¼ç™¾åˆ†æ¯” (%)", 
                        row=hist_row, col=hist_col
                    )
                    fig.update_yaxes(
                        title_text="é¢‘æ¬¡ / æ•°æ®ç‚¹", 
                        row=hist_row, col=hist_col
                    )
                
                # æ€§èƒ½ç»Ÿè®¡æŠ¥å‘Š
                negative_data = percentage_df[percentage_df['percentage_diff'] < 100]
                if not negative_data.empty:
                    negative_count = len(negative_data)
                    total_count = len(percentage_df)
                    negative_ratio = (negative_count / total_count) * 100
                    
                    print(f"âš ï¸  æ€§èƒ½ä½äºåŸºå‡†: {negative_count} ä¸ªæ•°æ®ç‚¹ ({negative_ratio:.1f}%)")
                    
                    # æŒ‰ç®—æ³•åˆ†ç»„æ˜¾ç¤ºè´Ÿå€¼ç»Ÿè®¡
                    neg_by_algo = negative_data.groupby('algorithm').size().sort_values(ascending=False)
                    for algo, count in neg_by_algo.head(3).items():
                        print(f"  {algo}: {count} ä¸ª")
            
            # æ·»åŠ ç½‘æ ¼åˆ°å‰ä¸¤ä¸ªå­å›¾
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=1, col=1)
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=1, col=1)
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=2, col=1)
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray', row=2, col=1)
            
        else:
            # å•GPUæ—¶çš„å¸ƒå±€è®¾ç½®
            fig.update_layout(
                title=dict(
                    text="GPU Performance - Single GPU Analysis",
                    x=0.5,
                    font=dict(size=20)
                ),
                xaxis=dict(
                    title=dict(text="Data Size (MB)", font=dict(size=14)),
                    type="log",
                    tickmode='array',
                    tickvals=[0.004, 0.016, 0.064, 0.256, 1, 4, 16, 64, 256, 1024, 2048, 4096],
                    ticktext=['4KB', '16KB', '64KB', '256KB', '1MB', '4MB', '16MB', '64MB', '256MB', '1GB', '2GB', '4GB']
                ),
                yaxis=dict(
                    title=dict(text="Throughput (GB/s)", font=dict(size=14)),
                    type="log"
                ),
                legend=dict(
                    orientation="v",
                    yanchor="top",
                    y=1,
                    xanchor="left",
                    x=1.02,
                    font=dict(size=11)
                ),
                width=width,
                height=total_height,
                hovermode='closest',
                plot_bgcolor='white',
                paper_bgcolor='white'
            )
            
            # æ·»åŠ ç½‘æ ¼
            fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
            fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='lightgray')
        
        # ä¿å­˜å›¾è¡¨
        if save_path:
            if save_path.endswith('.html'):
                # ç”ŸæˆåŒ…å«ç»Ÿè®¡è¡¨æ ¼çš„å®Œæ•´HTML
                self._write_html_with_statistics(fig, save_path, reference_lines)
                print(f"äº¤äº’å¼å›¾è¡¨å·²ä¿å­˜: {save_path}")
            else:
                fig.write_image(save_path, width=width, height=total_height)
                print(f"é™æ€å›¾è¡¨å·²ä¿å­˜: {save_path}")
        
        # ä¸è‡ªåŠ¨æ˜¾ç¤ºå›¾è¡¨ï¼Œé¿å…è¾“å‡ºHTMLå†…å®¹
        return fig

    def generate_statistics_tables(self, reference_lines: list = None) -> str:
        """ç”ŸæˆHTMLç»Ÿè®¡åˆ†ææ•°æ®è¡¨"""
        if not self.datasets:
            return "<p>æ— æ•°æ®å¯æ˜¾ç¤º</p>"
        
        # å¤„ç†å‚è€ƒçº¿é»˜è®¤å€¼
        if reference_lines is None:
            reference_lines = [100.0]
        
        html_content = []
        
        # è·å–åˆå¹¶æ•°æ®
        df = self.get_combined_dataframe()
        if df.empty:
            return "<p>æ— æ•°æ®å¯æ˜¾ç¤º</p>"
        
        gpu_labels = list(self.datasets.keys())
        algorithms = df['algorithm'].unique()
        
        # 1. GPUæ€§èƒ½å¯¹æ¯”æ€»è¡¨
        html_content.append('<div class="statistics-section">')
        html_content.append('<h3>ğŸ“Š GPUæ€§èƒ½å¯¹æ¯”æ€»è§ˆ</h3>')
        html_content.append('<table class="stats-table">')
        html_content.append('<thead><tr><th>GPU</th><th>æœ€é«˜ååé‡ (GB/s)</th><th>æ•°æ®ç‚¹æ•°é‡</th><th>è¦†ç›–ç®—æ³•</th></tr></thead>')
        html_content.append('<tbody>')
        
        for gpu in gpu_labels:
            gpu_data = df[df['gpu_label'] == gpu]
            if not gpu_data.empty:
                max_throughput = gpu_data['throughput'].max()
                max_row = gpu_data[gpu_data['throughput'] == max_throughput].iloc[0]
                data_count = len(gpu_data)
                
                # åˆ—å‡ºè¯¥GPUæµ‹è¯•çš„æ‰€æœ‰ç®—æ³•
                algorithms_tested = ', '.join(sorted(gpu_data['algorithm'].unique()))
                
                html_content.append(f'<tr>')
                html_content.append(f'<td><strong>{gpu}</strong></td>')
                html_content.append(f'<td>{max_throughput:.2f}<br><small>({max_row["algorithm"]}, {max_row["data_size"]:.0f}MB)</small></td>')
                html_content.append(f'<td>{data_count}</td>')
                html_content.append(f'<td><small>{algorithms_tested}</small></td>')
                html_content.append(f'</tr>')
        
        html_content.append('</tbody></table>')
        html_content.append('</div>')
        
        # 2. ç®—æ³•æ€§èƒ½èŒƒå›´åˆ†æè¡¨
        html_content.append('<div class="statistics-section">')
        html_content.append('<h3>ğŸ”¬ ç®—æ³•æ€§èƒ½èŒƒå›´åˆ†æ</h3>')
        html_content.append('<table class="stats-table">')
        html_content.append('<thead><tr><th>ç®—æ³•</th>')
        
        for gpu in gpu_labels:
            html_content.append(f'<th>{gpu}<br><small>æœ€é«˜(GB/s)</small></th>')
        
        html_content.append('<th>æ€»ä½“æœ€ä½³</th></tr></thead>')
        html_content.append('<tbody>')
        
        for algo in sorted(algorithms):
            html_content.append('<tr>')
            html_content.append(f'<td><strong>{algo}</strong></td>')
            
            algo_data = df[df['algorithm'] == algo]
            gpu_performances = []
            
            for gpu in gpu_labels:
                gpu_algo_data = algo_data[algo_data['gpu_label'] == gpu]
                if not gpu_algo_data.empty:
                    max_perf = gpu_algo_data['throughput'].max()
                    gpu_performances.append((gpu, max_perf))
                    html_content.append(f'<td>{max_perf:.2f}</td>')
                else:
                    gpu_performances.append((gpu, 0))
                    html_content.append(f'<td>-</td>')
            
            # æœ€ä½³GPU
            if gpu_performances:
                best_gpu = max(gpu_performances, key=lambda x: x[1])
                if best_gpu[1] > 0:
                    html_content.append(f'<td><span class="best-gpu">{best_gpu[0]}</span><br><small>{best_gpu[1]:.2f}</small></td>')
                else:
                    html_content.append(f'<td>-</td>')
            else:
                html_content.append(f'<td>-</td>')
                
            html_content.append('</tr>')
        
        html_content.append('</tbody></table>')
        html_content.append('</div>')
        
        # 3. æ€§èƒ½å·®å¼‚åˆ†æè¡¨ï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
        if len(gpu_labels) > 1:
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            if percentage_df is not None and not percentage_df.empty:
                html_content.append('<div class="statistics-section">')
                html_content.append('<h3>ğŸ“ˆ æ€§èƒ½å·®å¼‚åˆ†æ</h3>')
                
                baseline_gpu = gpu_labels[0]
                comparison_gpus = gpu_labels[1:]
                
                for i, gpu in enumerate(comparison_gpus):
                    gpu_diff_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    if gpu_diff_data.empty:
                        continue
                    
                    # è·å–å½“å‰å¯¹æ¯”ç»„çš„å‚è€ƒçº¿
                    if len(reference_lines) == 1:
                        # å•ä¸ªå‚è€ƒçº¿ï¼Œå¯¹æ‰€æœ‰å¯¹æ¯”ç»„ä½¿ç”¨
                        current_ref_line = reference_lines[0]
                    else:
                        # å¤šä¸ªå‚è€ƒçº¿ï¼Œæ¯ä¸ªå¯¹æ¯”ç»„ä½¿ç”¨å¯¹åº”çš„å‚è€ƒçº¿
                        current_ref_line = reference_lines[i] if i < len(reference_lines) else reference_lines[-1]
                        
                    html_content.append(f'<h4>{gpu} vs {baseline_gpu} (å‚è€ƒçº¿: {current_ref_line}%)</h4>')
                    html_content.append('<table class="stats-table">')
                    html_content.append('<thead><tr><th>ç»Ÿè®¡æŒ‡æ ‡</th><th>æ•°å€¼</th><th>è¯´æ˜</th></tr></thead>')
                    html_content.append('<tbody>')
                    
                    # åŸºæœ¬ç»Ÿè®¡
                    mean_diff = gpu_diff_data['percentage_diff'].mean()
                    median_diff = gpu_diff_data['percentage_diff'].median()
                    std_diff = gpu_diff_data['percentage_diff'].std()
                    min_diff = gpu_diff_data['percentage_diff'].min()
                    max_diff = gpu_diff_data['percentage_diff'].max()
                    
                    # åŸºäºå‚è€ƒçº¿çš„æ€§èƒ½åˆ†æ
                    above_ref_count = len(gpu_diff_data[gpu_diff_data['percentage_diff'] > current_ref_line])
                    below_ref_count = len(gpu_diff_data[gpu_diff_data['percentage_diff'] < current_ref_line])
                    total_count = len(gpu_diff_data)
                    
                    # æ€§èƒ½ä¼˜åŠ¿ç»Ÿè®¡ (ç°åœ¨100%ä¸ºåŸºå‡†)
                    positive_count = len(gpu_diff_data[gpu_diff_data['percentage_diff'] > 100])
                    negative_count = len(gpu_diff_data[gpu_diff_data['percentage_diff'] < 100])
                    
                    stats_data = [
                        ('å¹³å‡æ¯”å€¼', f'{mean_diff:.1f}%', 'å¤§äº100%è¡¨ç¤ºæ€§èƒ½æå‡ï¼Œå°äº100%è¡¨ç¤ºæ€§èƒ½ä¸‹é™'),
                        ('ä¸­ä½æ•°æ¯”å€¼', f'{median_diff:.1f}%', '50%çš„æµ‹è¯•ç‚¹æ€§èƒ½æ¯”å€¼åœ¨æ­¤å€¼ä»¥ä¸‹'),
                        ('æ ‡å‡†å·®', f'{std_diff:.1f}%', 'æ€§èƒ½æ¯”å€¼çš„ç¦»æ•£ç¨‹åº¦'),
                        ('æœ€é«˜æ¯”å€¼', f'{max_diff:.1f}%', 'å•ä¸ªæµ‹è¯•ç‚¹çš„æœ€é«˜æ€§èƒ½æ¯”å€¼'),
                        ('æœ€ä½æ¯”å€¼', f'{min_diff:.1f}%', 'å•ä¸ªæµ‹è¯•ç‚¹çš„æœ€ä½æ€§èƒ½æ¯”å€¼'),
                        ('', '', ''),  # åˆ†éš”çº¿
                        ('é«˜äºå‚è€ƒçº¿æ¯”ä¾‹', f'{above_ref_count}/{total_count} ({100*above_ref_count/total_count:.1f}%)', f'æ€§èƒ½æ¯”å€¼>{current_ref_line}%çš„æµ‹è¯•ç‚¹æ¯”ä¾‹'),
                        ('ä½äºå‚è€ƒçº¿æ¯”ä¾‹', f'{below_ref_count}/{total_count} ({100*below_ref_count/total_count:.1f}%)', f'æ€§èƒ½æ¯”å€¼<{current_ref_line}%çš„æµ‹è¯•ç‚¹æ¯”ä¾‹'),
                        ('', '', ''),  # åˆ†éš”çº¿
                        ('æ€§èƒ½ä¼˜äºåŸºå‡†æ¯”ä¾‹', f'{positive_count}/{total_count} ({100*positive_count/total_count:.1f}%)', 'æ€§èƒ½æ¯”å€¼>100%çš„æµ‹è¯•ç‚¹æ¯”ä¾‹'),
                        ('æ€§èƒ½ä½äºåŸºå‡†æ¯”ä¾‹', f'{negative_count}/{total_count} ({100*negative_count/total_count:.1f}%)', 'æ€§èƒ½æ¯”å€¼<100%çš„æµ‹è¯•ç‚¹æ¯”ä¾‹')
                    ]
                    
                    for stat_name, stat_value, stat_desc in stats_data:
                        color_class = ""
                        # ä¸ºç©ºè¡Œæä¾›åˆ†éš”æ ·å¼
                        if stat_name == "" and stat_value == "":
                            html_content.append(f'<tr style="height: 8px;"><td colspan="3" style="border: none; background: #f8f9fa;"></td></tr>')
                            continue
                            
                        if "ä¼˜äº" in stat_name and positive_count > negative_count:
                            color_class = ' class="positive"'
                        elif "ä½äº" in stat_name and negative_count > positive_count:
                            color_class = ' class="negative"'
                        elif "é«˜äºå‚è€ƒçº¿" in stat_name and above_ref_count > below_ref_count:
                            color_class = ' class="positive"'
                        elif "ä½äºå‚è€ƒçº¿" in stat_name and below_ref_count > above_ref_count:
                            color_class = ' class="negative"'
                            
                        html_content.append(f'<tr>')
                        html_content.append(f'<td><strong>{stat_name}</strong></td>')
                        html_content.append(f'<td{color_class}><strong>{stat_value}</strong></td>')
                        html_content.append(f'<td><small>{stat_desc}</small></td>')
                        html_content.append(f'</tr>')
                    
                    html_content.append('</tbody></table><br>')
                
                html_content.append('</div>')
        
        # 4. æ•°æ®è§„æ¨¡æ€§èƒ½åˆ†æè¡¨
        html_content.append('<div class="statistics-section">')
        html_content.append('<h3>ğŸ“ æ•°æ®è§„æ¨¡æ€§èƒ½åˆ†æ</h3>')
        html_content.append('<table class="stats-table">')
        html_content.append('<thead><tr><th>æ•°æ®è§„æ¨¡</th>')
        
        for gpu in gpu_labels:
            html_content.append(f'<th>{gpu}<br><small>æœ€é«˜ (GB/s)</small></th>')
        
        html_content.append('<th>æœ€ä½³è¡¨ç°</th></tr></thead>')
        html_content.append('<tbody>')
        
        data_sizes = sorted(df['data_size'].unique())
        for size in data_sizes:
            size_data = df[df['data_size'] == size]
            
            # æ ¼å¼åŒ–æ•°æ®è§„æ¨¡æ˜¾ç¤º
            if size < 1:
                size_label = f"{int(size * 1024)}KB"
            elif size < 1024:
                size_label = f"{int(size)}MB"
            else:
                size_label = f"{int(size / 1024)}GB"
            
            html_content.append('<tr>')
            html_content.append(f'<td><strong>{size_label}</strong></td>')
            
            size_performances = []
            
            for gpu in gpu_labels:
                gpu_size_data = size_data[size_data['gpu_label'] == gpu]
                if not gpu_size_data.empty:
                    max_perf = gpu_size_data['throughput'].max()
                    size_performances.append((gpu, max_perf))
                    html_content.append(f'<td>{max_perf:.2f}</td>')
                else:
                    size_performances.append((gpu, 0))
                    html_content.append(f'<td>-</td>')
            
            # æœ€ä½³è¡¨ç°
            if size_performances:
                best_gpu_size = max(size_performances, key=lambda x: x[1])
                if best_gpu_size[1] > 0:
                    html_content.append(f'<td><span class="best-gpu">{best_gpu_size[0]}</span><br><small>{best_gpu_size[1]:.2f}</small></td>')
                else:
                    html_content.append(f'<td>-</td>')
            else:
                html_content.append(f'<td>-</td>')
                
            html_content.append('</tr>')
        
        html_content.append('</tbody></table>')
        html_content.append('</div>')
        
        # 5. æç«¯å’Œå¼‚å¸¸æ•°æ®æŠ¥å‘Šï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
        if len(gpu_labels) > 1:
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            
            # æç«¯æ•°æ®å±•ç¤º
            if extreme_data:
                html_content.append('<div class="statistics-section">')
                html_content.append('<h3>âš ï¸ æç«¯æ€§èƒ½æ¯”å€¼æ•°æ® (>300% æˆ– <33%)</h3>')
                html_content.append(f'<p><small>å…±å‘ç° <strong>{len(extreme_data)}</strong> ä¸ªæç«¯æ€§èƒ½æ¯”å€¼æ•°æ®ç‚¹ï¼Œå·²ä»å¸¸è§„å¯¹æ¯”åˆ†æä¸­æ’é™¤</small></p>')
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºæç«¯æ•°æ®
                extreme_by_gpu = {}
                for item in extreme_data:
                    gpu = item['gpu_label']
                    if gpu not in extreme_by_gpu:
                        extreme_by_gpu[gpu] = []
                    extreme_by_gpu[gpu].append(item)
                
                for gpu, gpu_extreme_data in extreme_by_gpu.items():
                    html_content.append(f'<h4>{gpu} vs {gpu_labels[0]} - æç«¯æ¡ˆä¾‹ ({len(gpu_extreme_data)} ä¸ª)</h4>')
                    html_content.append('<table class="stats-table">')
                    html_content.append('<thead><tr><th>ç®—æ³•</th><th>æ•°æ®è§„æ¨¡</th><th>æ€§èƒ½æ¯”å€¼</th><th>åŸºå‡†å€¼</th><th>å¯¹æ¯”å€¼</th></tr></thead>')
                    html_content.append('<tbody>')
                    
                    # æŒ‰å·®å¼‚ç¨‹åº¦æ’åºï¼Œåªæ˜¾ç¤ºå‰10ä¸ª
                    gpu_extreme_data.sort(key=lambda x: abs(x['percentage_diff'] - 100), reverse=True)
                    for item in gpu_extreme_data[:10]:
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        
                        diff_class = 'positive' if item['percentage_diff'] > 100 else 'negative'
                        html_content.append('<tr>')
                        html_content.append(f'<td>{item["algorithm"]}</td>')
                        html_content.append(f'<td>{data_size_label}</td>')
                        html_content.append(f'<td class="{diff_class}"><strong>{item["percentage_diff"]:.1f}%</strong></td>')
                        html_content.append(f'<td>{item["baseline_throughput"]:.2f} GB/s</td>')
                        html_content.append(f'<td>{item["comparison_throughput"]:.2f} GB/s</td>')
                        html_content.append('</tr>')
                    
                    if len(gpu_extreme_data) > 10:
                        html_content.append(f'<tr><td colspan="5"><small><em>... è¿˜æœ‰ {len(gpu_extreme_data) - 10} ä¸ªæç«¯æ¡ˆä¾‹</em></small></td></tr>')
                    
                    html_content.append('</tbody></table><br>')
                
                html_content.append('</div>')
            
            # å¼‚å¸¸æ•°æ®å±•ç¤º
            if anomaly_data:
                html_content.append('<div class="statistics-section">')
                html_content.append('<h3>ğŸš« å¼‚å¸¸æ•°æ® (æ— æ•ˆå€¼)</h3>')
                html_content.append(f'<p><small>å…±å‘ç° <strong>{len(anomaly_data)}</strong> ä¸ªåŒ…å«æ— æ•ˆå€¼çš„æ•°æ®ç‚¹ï¼Œå·²ä»æ‰€æœ‰åˆ†æä¸­æ’é™¤</small></p>')
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºå¼‚å¸¸æ•°æ®
                anomaly_by_gpu = {}
                for item in anomaly_data:
                    gpu = item['gpu_label']
                    if gpu not in anomaly_by_gpu:
                        anomaly_by_gpu[gpu] = []
                    anomaly_by_gpu[gpu].append(item)
                
                for gpu, gpu_anomaly_data in anomaly_by_gpu.items():
                    html_content.append(f'<h4>{gpu} vs {gpu_labels[0]} - å¼‚å¸¸æ¡ˆä¾‹ ({len(gpu_anomaly_data)} ä¸ª)</h4>')
                    html_content.append('<table class="stats-table">')
                    html_content.append('<thead><tr><th>ç®—æ³•</th><th>æ•°æ®è§„æ¨¡</th><th>å¼‚å¸¸åŸå› </th><th>åŸºå‡†å€¼</th><th>å¯¹æ¯”å€¼</th></tr></thead>')
                    html_content.append('<tbody>')
                    
                    # åªæ˜¾ç¤ºå‰15ä¸ªå¼‚å¸¸æ¡ˆä¾‹
                    for item in gpu_anomaly_data[:15]:
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        
                        html_content.append('<tr>')
                        html_content.append(f'<td>{item["algorithm"]}</td>')
                        html_content.append(f'<td>{data_size_label}</td>')
                        html_content.append(f'<td class="negative"><small>{item["reason"]}</small></td>')
                        html_content.append(f'<td>{item["baseline_throughput"]:.2f} GB/s</td>')
                        html_content.append(f'<td>{item["comparison_throughput"]:.2f} GB/s</td>')
                        html_content.append('</tr>')
                    
                    if len(gpu_anomaly_data) > 15:
                        html_content.append(f'<tr><td colspan="5"><small><em>... è¿˜æœ‰ {len(gpu_anomaly_data) - 15} ä¸ªå¼‚å¸¸æ¡ˆä¾‹</em></small></td></tr>')
                    
                    html_content.append('</tbody></table><br>')
                
                html_content.append('</div>')
        
        return '\n'.join(html_content)

    def _get_html_styles(self) -> str:
        """è·å–è¡¨æ ¼æ ·å¼CSS"""
        return """
        <style>
        .statistics-container {
            max-width: 1200px;
            margin: 20px auto;
            padding: 20px;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background-color: #f8f9fa;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        
        .statistics-section {
            margin-bottom: 30px;
            background: white;
            padding: 20px;
            border-radius: 6px;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
        }
        
        .statistics-section h3 {
            color: #2c3e50;
            border-bottom: 3px solid #3498db;
            padding-bottom: 10px;
            margin-top: 0;
            font-size: 1.4em;
        }
        
        .statistics-section h4 {
            color: #34495e;
            margin-top: 25px;
            margin-bottom: 15px;
            font-size: 1.2em;
            border-left: 4px solid #e74c3c;
            padding-left: 12px;
        }
        
        .stats-table {
            width: 100%;
            border-collapse: collapse;
            margin-top: 15px;
            font-size: 0.9em;
        }
        
        .stats-table th {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 12px 8px;
            text-align: center;
            font-weight: 600;
            border: 1px solid #ddd;
            font-size: 0.85em;
        }
        
        .stats-table td {
            padding: 10px 8px;
            text-align: center;
            border: 1px solid #ddd;
            background-color: #fff;
        }
        
        .stats-table tbody tr:nth-child(even) {
            background-color: #f8f9fa;
        }
        
        .stats-table tbody tr:hover {
            background-color: #e8f4f8;
            transition: background-color 0.2s;
        }
        
        .best-gpu {
            background: linear-gradient(45deg, #28a745, #20c997);
            color: white;
            padding: 3px 8px;
            border-radius: 12px;
            font-weight: bold;
            font-size: 0.8em;
            display: inline-block;
        }
        
        .positive {
            color: #28a745;
            font-weight: bold;
        }
        
        .negative {
            color: #dc3545;
            font-weight: bold;
        }
        
        .stats-table td small {
            color: #6c757d;
            font-size: 0.8em;
            display: block;
            margin-top: 2px;
        }
        
        .stats-table th small {
            font-weight: normal;
            font-size: 0.75em;
            opacity: 0.9;
        }
        
        /* å“åº”å¼è®¾è®¡ */
        @media (max-width: 768px) {
            .statistics-container {
                margin: 10px;
                padding: 10px;
            }
            
            .stats-table {
                font-size: 0.8em;
            }
            
            .stats-table th,
            .stats-table td {
                padding: 6px 4px;
            }
        }
        </style>
        """

    def _write_html_with_statistics(self, fig, save_path: str, reference_lines: list = None):
        """å°†å›¾è¡¨å’Œç»Ÿè®¡è¡¨æ ¼å†™å…¥HTMLæ–‡ä»¶"""
        import tempfile
        import os
        
        # å…ˆå°†å›¾è¡¨ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(mode='w', suffix='.html', delete=False) as tmp_file:
            fig.write_html(tmp_file.name)
            
            # è¯»å–Plotlyç”Ÿæˆçš„HTMLå†…å®¹
            with open(tmp_file.name, 'r', encoding='utf-8') as f:
                plotly_html = f.read()
        
        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        os.unlink(tmp_file.name)
        
        # ç”Ÿæˆç»Ÿè®¡è¡¨æ ¼
        statistics_html = self.generate_statistics_tables(reference_lines)
        
        # è·å–æ ·å¼
        styles = self._get_html_styles()
        
        # åœ¨Plotly HTMLä¸­æ’å…¥ç»Ÿè®¡è¡¨æ ¼å’Œæ ·å¼
        # æ‰¾åˆ°</head>æ ‡ç­¾ï¼Œåœ¨ä¹‹å‰æ’å…¥æ ·å¼
        if '</head>' in plotly_html:
            plotly_html = plotly_html.replace('</head>', f'{styles}</head>')
        
        # æ‰¾åˆ°</body>æ ‡ç­¾ï¼Œåœ¨ä¹‹å‰æ’å…¥ç»Ÿè®¡è¡¨æ ¼
        statistics_section = f'''
        <div class="statistics-container">
            <h2 style="text-align: center; color: #2c3e50; margin-bottom: 30px;">
                ğŸ“ˆ GPUæ€§èƒ½ç»Ÿè®¡åˆ†ææŠ¥å‘Š
            </h2>
            {statistics_html}
        </div>
        '''
        
        if '</body>' in plotly_html:
            plotly_html = plotly_html.replace('</body>', f'{statistics_section}</body>')
        
        # å†™å…¥æœ€ç»ˆçš„HTMLæ–‡ä»¶
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(plotly_html)

    def generate_summary_report(self, reference_lines: list = None) -> str:
        """ç”Ÿæˆæ€§èƒ½åˆ†ææ€»ç»“æŠ¥å‘Š"""
        df = self.get_combined_dataframe()
        
        if df.empty:
            return "æ²¡æœ‰æ•°æ®å¯ä»¥åˆ†æ"
        
        # å¤„ç†å‚è€ƒçº¿é»˜è®¤å€¼
        if reference_lines is None:
            reference_lines = [100.0]
        
        report = []
        report.append("=" * 50)
        report.append("Performance Analysis Report")
        report.append("=" * 50)
        report.append(f"Total samples: {len(df)}")
        report.append(f"Algorithms tested: {', '.join(df['algorithm'].unique())}")
        report.append(f"GPU labels: {', '.join(df['gpu_label'].unique())}")
        report.append(f"Data sizes: {', '.join(map(str, df['data_size'].unique()))}")
        report.append("")
        
        # æœ€ä½³æ€§èƒ½ç»Ÿè®¡
        best_perf = df.loc[df['throughput'].idxmax()]
        report.append("Best Performance:")
        report.append(f"  Algorithm: {best_perf['algorithm']}")
        report.append(f"  GPU: {best_perf['gpu_label']}")
        report.append(f"  Data Size: {best_perf['data_size']}")
        report.append(f"  Throughput: {best_perf['throughput']:.2f} GB/s")
        report.append("")
        
        # å„GPUæœ€ä½³æ€§èƒ½
        report.append("Best Performance by GPU:")
        for gpu in df['gpu_label'].unique():
            gpu_data = df[df['gpu_label'] == gpu]
            max_perf = gpu_data['throughput'].max()
            max_row = gpu_data[gpu_data['throughput'] == max_perf].iloc[0]
            report.append(f"  {gpu}: {max_perf:.2f} GB/s ({max_row['algorithm']}, {max_row['data_size']:.0f}MB)")
        report.append("")
        
        # æ€§èƒ½ç™¾åˆ†æ¯”å·®å¼‚åˆ†æï¼ˆå¦‚æœæœ‰å¤šä¸ªGPUï¼‰
        gpu_labels = df['gpu_label'].unique()
        if len(gpu_labels) > 1:
            report.append("Performance Percentage Ratios:")
            report.append(f"  Baseline GPU: {gpu_labels[0]}")
            report.append("")
            
            percentage_df, extreme_data, anomaly_data = self.calculate_percentage_differences()
            if percentage_df is not None:
                comparison_gpus = gpu_labels[1:]
                for i, gpu in enumerate(comparison_gpus):
                    gpu_data = percentage_df[percentage_df['gpu_label'] == gpu]
                    if not gpu_data.empty:
                        # è·å–å½“å‰å¯¹æ¯”ç»„çš„å‚è€ƒçº¿
                        if len(reference_lines) == 1:
                            current_ref_line = reference_lines[0]
                        else:
                            current_ref_line = reference_lines[i] if i < len(reference_lines) else reference_lines[-1]
                        
                        max_diff = gpu_data['percentage_diff'].max()
                        min_diff = gpu_data['percentage_diff'].min()
                        median_diff = gpu_data['percentage_diff'].median()
                        
                        # åŸºäºå‚è€ƒçº¿çš„ç»Ÿè®¡
                        above_ref_count = len(gpu_data[gpu_data['percentage_diff'] > current_ref_line])
                        below_ref_count = len(gpu_data[gpu_data['percentage_diff'] < current_ref_line])
                        total_count = len(gpu_data)
                        
                        report.append(f"  {gpu} vs {gpu_labels[0]} (Reference: {current_ref_line}%):")
                        report.append(f"    Max Ratio: {max_diff:.1f}%")
                        report.append(f"    Min Ratio: {min_diff:.1f}%")
                        report.append(f"    Median Ratio: {median_diff:.1f}%")
                        report.append(f"    Above Reference: {above_ref_count}/{total_count} ({100*above_ref_count/total_count:.1f}%)")
                        report.append(f"    Below Reference: {below_ref_count}/{total_count} ({100*below_ref_count/total_count:.1f}%)")
                        report.append("")
            
            # æ·»åŠ æç«¯æ•°æ®æŠ¥å‘Š
            if extreme_data:
                report.append("Extreme Performance Ratios (>300% or <33%):")
                report.append(f"  Total extreme data points: {len(extreme_data)}")
                report.append("")
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºæç«¯æ•°æ®
                extreme_by_gpu = {}
                for item in extreme_data:
                    gpu = item['gpu_label']
                    if gpu not in extreme_by_gpu:
                        extreme_by_gpu[gpu] = []
                    extreme_by_gpu[gpu].append(item)
                
                for gpu, gpu_extreme_data in extreme_by_gpu.items():
                    report.append(f"  {gpu} vs {gpu_labels[0]} - Extreme Cases:")
                    # æŒ‰å·®å¼‚ç¨‹åº¦æ’åº
                    gpu_extreme_data.sort(key=lambda x: abs(x['percentage_diff'] - 100), reverse=True)
                    
                    for item in gpu_extreme_data[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªæœ€æç«¯çš„
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        report.append(f"    {item['algorithm']} ({data_size_label}): {item['percentage_diff']:.1f}% "
                                    f"({item['baseline_throughput']:.2f} â†’ {item['comparison_throughput']:.2f} GB/s)")
                    
                    if len(gpu_extreme_data) > 10:
                        report.append(f"    ... and {len(gpu_extreme_data) - 10} more extreme cases")
                    report.append("")
            
            # æ·»åŠ å¼‚å¸¸æ•°æ®æŠ¥å‘Š
            if anomaly_data:
                report.append("Anomalous Data (invalid values):")
                report.append(f"  Total anomalous data points: {len(anomaly_data)}")
                report.append("")
                
                # æŒ‰GPUåˆ†ç»„æ˜¾ç¤ºå¼‚å¸¸æ•°æ®
                anomaly_by_gpu = {}
                for item in anomaly_data:
                    gpu = item['gpu_label']
                    if gpu not in anomaly_by_gpu:
                        anomaly_by_gpu[gpu] = []
                    anomaly_by_gpu[gpu].append(item)
                
                for gpu, gpu_anomaly_data in anomaly_by_gpu.items():
                    report.append(f"  {gpu} vs {gpu_labels[0]} - Anomalous Cases:")
                    
                    for item in gpu_anomaly_data[:15]:  # åªæ˜¾ç¤ºå‰15ä¸ªå¼‚å¸¸æ¡ˆä¾‹
                        data_size_label = f"{int(item['data_size'] * 1024)}KB" if item['data_size'] < 1 else \
                                        f"{int(item['data_size'])}MB" if item['data_size'] < 1024 else \
                                        f"{int(item['data_size'] / 1024)}GB"
                        report.append(f"    {item['algorithm']} ({data_size_label}): {item['reason']} "
                                    f"({item['baseline_throughput']:.2f} vs {item['comparison_throughput']:.2f} GB/s)")
                    
                    if len(gpu_anomaly_data) > 15:
                        report.append(f"    ... and {len(gpu_anomaly_data) - 15} more anomalous cases")
                    report.append("")
        
        # å„ç®—æ³•æœ€ä½³æ€§èƒ½
        report.append("Best Performance by Algorithm:")
        for algo in df['algorithm'].unique():
            algo_data = df[df['algorithm'] == algo]
            max_perf = algo_data['throughput'].max()
            max_row = algo_data[algo_data['throughput'] == max_perf].iloc[0]
            report.append(f"  {algo}: {max_perf:.2f} GB/s ({max_row['gpu_label']}, {max_row['data_size']:.0f}MB)")
        
        return "\n".join(report)


def create_comprehensive_datasets(scale_factor=1.0):
    """åˆ›å»ºç»¼åˆæ€§èƒ½æ•°æ®é›†ï¼ŒåŒ…å«æ›´å¤šç®—æ³•ç±»åˆ«å’Œæ•°æ®è§„æ¨¡
    
    Args:
        scale_factor: æ•°æ®é‡ç¼©æ”¾ç³»æ•°ï¼Œ1.0=å®Œæ•´æ•°æ®é›†ï¼Œ0.1=æµ‹è¯•ç”¨å°æ•°æ®é›†
    """
    
    # CUBå’ŒThrustç›¸å…³çš„GPUå¹¶è¡Œè®¡ç®—ç®—æ³•
    algorithms = {
        # CUBæ ¸å¿ƒç®—æ³•
        'cub_reduce': 'CUB Reduce',
        'cub_scan': 'CUB Scan/Prefix Sum',
        'cub_sort': 'CUB Radix Sort',
        'cub_histogram': 'CUB Histogram',
        'cub_select': 'CUB Stream Compaction',
        
        # Thrustç®—æ³•
        'thrust_reduce': 'Thrust Reduce',
        'thrust_scan': 'Thrust Scan',
        'thrust_sort': 'Thrust Sort',
        'thrust_transform': 'Thrust Transform',
        'thrust_copy_if': 'Thrust Copy If',
        
        # ç»„åˆç®—æ³•
        'reduce_by_key': 'Reduce By Key',
        'unique': 'Unique/Adjacent Difference',
        'partition': 'Partition',
        'merge': 'Merge',
        'set_operations': 'Set Operations'
    }
    
    # æ‰©å±•çš„æ•°æ®è§„æ¨¡èŒƒå›´ (å‡ KBåˆ°å‡ GB) - ä»¥MBä¸ºå•ä½çš„æ•°å€¼ï¼Œä»¥2å€é€’å¢
    # å¢å¼ºçš„æ•°æ®é‡‡æ ·ï¼š1kèµ·å§‹ï¼Œ4GBç»“æŸï¼ŒåˆæœŸå¯†é›†é‡‡æ ·
    base_sizes = [1.0, 1.2, 1.6, 1.8]  # åˆæœŸåŸºç¡€ç‚¹ï¼š1MB, 1.2MB, 1.6MB, 1.8MB
    
    # ç”Ÿæˆå®Œæ•´çš„æ•°æ®è§„æ¨¡åºåˆ—
    data_sizes_mb = []
    
    # æ·»åŠ åˆæœŸåŸºç¡€ç‚¹åŠå…¶2å€æ‰©å±•åºåˆ—
    for base in base_sizes:
        current = base
        while current <= 4096:  # æ‰©å±•åˆ°4GB
            data_sizes_mb.append(current)
            current *= 2
    
    # åœ¨1-4GBèŒƒå›´å†…å¢åŠ æ›´å¤šé‡‡æ ·å¯†åº¦
    additional_1gb_4gb = [
        1024, 1280, 1536, 1792,  # 1GB-1.75GB èŒƒå›´
        2048, 2304, 2560, 2816, 3072, 3328, 3584, 3840,  # 2GB-3.75GB èŒƒå›´  
        4096  # 4GB
    ]
    
    # åˆå¹¶å¹¶å»é‡æ’åº
    data_sizes_mb.extend(additional_1gb_4gb)
    data_sizes_mb = sorted(list(set(data_sizes_mb)))
    
    # ç”Ÿæˆå¯¹åº”çš„æ˜¾ç¤ºæ ‡ç­¾
    data_size_labels = []
    for size_mb in data_sizes_mb:
        if size_mb < 1:
            data_size_labels.append(f'{int(size_mb * 1024)}KB')
        elif size_mb < 1024:
            if size_mb == int(size_mb):
                data_size_labels.append(f'{int(size_mb)}MB')
            else:
                data_size_labels.append(f'{size_mb:.1f}MB')
        else:
            gb_size = size_mb / 1024
            if gb_size == int(gb_size):
                data_size_labels.append(f'{int(gb_size)}GB')
            else:
                data_size_labels.append(f'{gb_size:.1f}GB')
    
    # æ ¹æ®scale_factorè°ƒæ•´æ•°æ®è§„æ¨¡
    if scale_factor < 1.0:
        # æµ‹è¯•æ¨¡å¼ï¼šå‡å°‘ç®—æ³•å’Œæ•°æ®è§„æ¨¡
        algorithm_count = max(3, int(len(algorithms) * scale_factor))
        data_size_count = max(5, int(len(data_sizes_mb) * scale_factor))
        
        selected_algorithms = dict(list(algorithms.items())[:algorithm_count])
        selected_data_sizes = [data_sizes_mb[i] for i in range(0, len(data_sizes_mb), max(1, len(data_sizes_mb) // data_size_count))][:data_size_count]
        selected_labels = [data_size_labels[i] for i in range(0, len(data_size_labels), max(1, len(data_size_labels) // data_size_count))][:data_size_count]
        
        print(f"æµ‹è¯•æ¨¡å¼ (scale={scale_factor}): {len(selected_algorithms)} ç§ç®—æ³•, {len(selected_data_sizes)} ä¸ªæ•°æ®è§„æ¨¡")
    else:
        # å®Œæ•´æ¨¡å¼
        selected_algorithms = algorithms
        selected_data_sizes = data_sizes_mb
        selected_labels = data_size_labels
    
    # GPUå‹å·åŠå…¶æ€§èƒ½ç‰¹å¾ (æµ‹è¯•5ä¸ªGPU)
    gpu_configs = {
        'RTX_4090': {
            'name': 'RTX_4090',
            'memory_bandwidth': 1008,  # GB/s
            'compute_units': 128,
            'base_clock': 2230,  # MHz
            'memory_size': 24,   # GB
        },
        'A100': {
            'name': 'A100',
            'memory_bandwidth': 1935,
            'compute_units': 108,
            'base_clock': 1410,
            'memory_size': 80,
        },
        'H100': {
            'name': 'H100',
            'memory_bandwidth': 3350,
            'compute_units': 132,
            'base_clock': 1980,
            'memory_size': 80,
        },
        'X500': {
            'name': 'X500',
            'memory_bandwidth': 1548,  # çº¦A100çš„80%
            'compute_units': 96,
            'base_clock': 1300,
            'memory_size': 64,
        },
        'X500_optimized': {
            'name': 'X500_optimized',
            'memory_bandwidth': 1548,  # ä¸X500ç›¸åŒçš„ç¡¬ä»¶
            'compute_units': 96,
            'base_clock': 1300,
            'memory_size': 64,
        },
        'X600': {
            'name': 'X600',
            'memory_bandwidth': 968,   # çº¦A100çš„50%
            'compute_units': 72,
            'base_clock': 1100,
            'memory_size': 48,
        }
    }
    
    np.random.seed(42)
    
    def mb_to_bytes(size_mb):
        """å°†MBä¸ºå•ä½çš„æ•°å€¼è½¬æ¢ä¸ºå­—èŠ‚æ•°"""
        return size_mb * 1024 * 1024
    
    def calculate_roofline_performance(algorithm, data_size_mb, gpu_config):
        """ç®€åŒ–çš„rooflineæ¨¡å‹ï¼šy=a*x çº¿æ€§å…³ç³»"""
        
        # ç®—æ³•ç‰¹æ€§ç³»æ•° - ä¸åŒç®—æ³•æœ‰ä¸åŒçš„çº¿æ€§ç³»æ•°ï¼Œå¯èƒ½äº’æœ‰èƒœè´Ÿ
        algorithm_coefficients = {
            # CUBæ ¸å¿ƒç®—æ³•
            'cub_reduce': 8.2, 'cub_scan': 7.5, 'cub_sort': 6.8, 'cub_histogram': 5.9, 'cub_select': 6.4,
            # Thrustç®—æ³•
            'thrust_reduce': 8.0, 'thrust_scan': 7.8, 'thrust_sort': 6.5, 'thrust_transform': 9.1, 'thrust_copy_if': 7.2,
            # ç»„åˆç®—æ³•
            'reduce_by_key': 7.6, 'unique': 7.0, 'partition': 6.8, 'merge': 8.5, 'set_operations': 7.4
        }
        
        # GPUå·®å¼‚ç³»æ•°
        gpu_multipliers = {
            'RTX_4090': 1.0,        # åŸºå‡†
            'A100': 1.08,           # ç¨é«˜8%
            'H100': 1.04,           # ç¨é«˜4%
            'X500': 0.85,           # çº¦85%æ€§èƒ½
            'X500_optimized': 1.0,  # è½¯ä»¶ä¼˜åŒ–åè¾¾åˆ°åŸºå‡†æ°´å¹³
            'X600': 0.52            # çº¦52%æ€§èƒ½
        }
        
        # è·å–ç®—æ³•ç³»æ•°å’ŒGPUç³»æ•°
        a = algorithm_coefficients.get(algorithm, 7.5)  # é»˜è®¤ç³»æ•°7.5
        gpu_factor = gpu_multipliers.get(gpu_config.get('name', 'RTX_4090'), 1.0)
        
        data_mb = data_size_mb
        
        if data_mb <= 64:  # <= 64MB: çº¯çº¿æ€§å…³ç³» y = a*x
            effective_bandwidth = a * gpu_factor * data_mb
        else:  # > 64MB: å¹³å°é˜¶æ®µ
            # å¹³å°å€¼åŸºäº64MBæ—¶çš„çº¿æ€§å€¼
            plateau_base = a * gpu_factor * 64
            effective_bandwidth = plateau_base * (0.95 + 0.1 * np.random.random())  # 95-105%éšæœºå˜åŒ–
        
        # æ·»åŠ å°é‡éšæœºå™ªå£°
        noise_factor = 1 + np.random.normal(0, 0.3)
        effective_bandwidth *= noise_factor
        
        return effective_bandwidth
    
    # ä¸ºæ¯ä¸ªGPUç”Ÿæˆæ•°æ®é›†
    datasets = {}
    
    for gpu_name, gpu_config in gpu_configs.items():
        print(f"ç”Ÿæˆ {gpu_name} æ•°æ®é›†...")
        gpu_data = []
        
        for algorithm in selected_algorithms.keys():
            for i, data_size_mb in enumerate(selected_data_sizes):
                # æ£€æŸ¥GPUå†…å­˜é™åˆ¶
                data_bytes = mb_to_bytes(data_size_mb)
                if data_bytes > gpu_config['memory_size'] * 1024**3:
                    continue  # è·³è¿‡è¶…å‡ºGPUå†…å­˜çš„æ•°æ®å¤§å°
                
                throughput = calculate_roofline_performance(algorithm, data_size_mb, gpu_config)
                
                gpu_data.append({
                    'algorithm': algorithm,
                    'data_size_mb': data_size_mb,  # æ•°å€¼å½¢å¼
                    'data_size_label': selected_labels[i] if i < len(selected_labels) else f"{data_size_mb}MB",  # æ˜¾ç¤ºæ ‡ç­¾
                    'throughput': max(throughput, 0.01)  # ç¡®ä¿éè´Ÿå€¼
                })
        
        # ä¿å­˜æ•°æ®é›† (ä¿å­˜æ•°å€¼æ ¼å¼çš„data_size_mbç”¨äºç»˜å›¾)
        df = pd.DataFrame(gpu_data)
        # ä¸ºäº†å…¼å®¹æ€§ï¼ŒCSVä¸­åªä¿å­˜algorithm, data_size_mb, throughput
        csv_df = df[['algorithm', 'data_size_mb', 'throughput']].rename(columns={'data_size_mb': 'data_size'})
        filename = f"{gpu_name.lower()}_performance.csv"
        csv_df.to_csv(filename, index=False)
        datasets[gpu_name] = df
        
        print(f"  - {filename}: {len(gpu_data)} æ¡è®°å½•")
    
    print(f"\nå…±ç”Ÿæˆ {len(datasets)} ä¸ªGPUæ•°æ®é›†ï¼Œè¦†ç›– {len(selected_algorithms)} ç§ç®—æ³•ç±»å‹")
    print(f"æ•°æ®è§„æ¨¡èŒƒå›´: {selected_labels[0]} - {selected_labels[-1]}")
    
    return datasets

def create_sample_datasets(scale_factor=1.0):
    """åˆ›å»ºç®€å•ç¤ºä¾‹æ•°æ®é›†ï¼ˆå‘åå…¼å®¹ï¼‰"""
    return create_comprehensive_datasets(scale_factor=scale_factor)


def main():
    parser = argparse.ArgumentParser(description='GPU Performance Comparison Tool')
    parser.add_argument('--csv-files', nargs='+',
                        help='CSV file paths')
    parser.add_argument('--labels', nargs='+',
                        help='Labels for each CSV file (e.g., GPU names)')
    parser.add_argument('--output', '-o', default='performance_comparison.html',
                        help='Output file path (default: performance_comparison.html)')
    parser.add_argument('--width', type=int, default=1200,
                        help='Chart width (default: 1200)')
    parser.add_argument('--height', type=int, default=800,
                        help='Chart height (default: 800)')
    parser.add_argument('--create-sample', action='store_true',
                        help='Create sample datasets and exit')
    parser.add_argument('--sample-scale', type=float, default=1.0,
                        help='Data generation scale factor (default: 1.0, use 0.2 for testing)')
    parser.add_argument('--reference-lines', nargs='+', type=float,
                        help='Reference lines for performance comparison (e.g., --reference-lines 80 90)')
    
    args = parser.parse_args()
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    if args.create_sample:
        create_sample_datasets(scale_factor=args.sample_scale)
        return
    
    # éªŒè¯å¿…éœ€å‚æ•°ï¼ˆä»…åœ¨æ²¡æœ‰åˆ›å»ºç¤ºä¾‹æ•°æ®æ—¶éœ€è¦ï¼‰
    if not args.create_sample and (not args.csv_files or not args.labels):
        print("é”™è¯¯: éœ€è¦æŒ‡å®š --csv-files å’Œ --labels å‚æ•°")
        print("ä½¿ç”¨ --help æŸ¥çœ‹å®Œæ•´å¸®åŠ©ä¿¡æ¯")
        print("æˆ–ä½¿ç”¨ --create-sample åˆ›å»ºç¤ºä¾‹æ•°æ®")
        sys.exit(1)
    
    # éªŒè¯å‚æ•°
    if len(args.csv_files) != len(args.labels):
        print("é”™è¯¯: CSVæ–‡ä»¶æ•°é‡ä¸æ ‡ç­¾æ•°é‡ä¸åŒ¹é…")
        sys.exit(1)
    
    # éªŒè¯æ–‡ä»¶å­˜åœ¨
    for csv_file in args.csv_files:
        if not Path(csv_file).exists():
            print(f"é”™è¯¯: æ–‡ä»¶ä¸å­˜åœ¨ {csv_file}")
            sys.exit(1)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = PerformanceAnalyzer()
    
    # åŠ è½½æ•°æ®é›†
    for csv_file, label in zip(args.csv_files, args.labels):
        analyzer.load_dataset(csv_file, label)
    
    if not analyzer.datasets:
        print("é”™è¯¯: æ²¡æœ‰æˆåŠŸåŠ è½½ä»»ä½•æ•°æ®é›†")
        sys.exit(1)
    
    # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    print("\næ­£åœ¨ç”Ÿæˆæ€§èƒ½å¯¹æ¯”å›¾è¡¨...")
    analyzer.create_comparison_line_chart(
        save_path=args.output,
        width=args.width,
        height=args.height,
        reference_lines=args.reference_lines
    )
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    print("\n" + analyzer.generate_summary_report(args.reference_lines))


if __name__ == "__main__":
    main()
